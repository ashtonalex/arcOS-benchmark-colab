{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQmG_saT2Xy9"
   },
   "source": [
    "# arcOS Benchmark - Causal QA with GNN + LLM\n",
    "\n",
    "**Phase 1: Environment & Data Foundation**\n",
    "\n",
    "This notebook implements the complete arcOS benchmark pipeline:\n",
    "- Graph Neural Network structural reasoning over knowledge graphs\n",
    "- LLM text generation with graph-guided prompts\n",
    "- Evaluation on RoG-WebQSP question answering dataset\n",
    "\n",
    "**Requirements:**\n",
    "- Google Colab with GPU runtime (T4 or better)\n",
    "- Google Drive mounted for checkpointing\n",
    "- ~10GB free space on Drive\n",
    "\n",
    "**Architecture:**\n",
    "- Dataset: RoG-WebQSP (4,706 QA pairs with Freebase subgraphs)\n",
    "- Graph DB: NetworkX in-memory\n",
    "- GNN: Graph Attention Network (GATv2)\n",
    "- LLM: OpenRouter API (Claude 3.5 Sonnet)\n",
    "- Verbalization: Hard prompts (text-based, not soft embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eazp1RCB1U8W"
   },
   "source": [
    "## Cell 0: Cloning Repository\n",
    "Update notebook with latest updates from GitHub repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Wsy7Km_P1U8X",
    "outputId": "ae37e605-33b3-41fb-c701-8adcf4f64072",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n",
      "Cloning into 'arcOS-benchmark-colab'...\n",
      "remote: Enumerating objects: 236, done.\u001b[K\n",
      "remote: Counting objects: 100% (236/236), done.\u001b[K\n",
      "remote: Compressing objects: 100% (148/148), done.\u001b[K\n",
      "remote: Total 236 (delta 125), reused 183 (delta 75), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (236/236), 229.72 KiB | 4.42 MiB/s, done.\n",
      "Resolving deltas: 100% (125/125), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure we are in a safe directory before operations\n",
    "%cd /content\n",
    "\n",
    "# Remove existing directory if it exists, then clone fresh\n",
    "!rm -rf arcOS-benchmark-colab\n",
    "!git clone https://github.com/ashtonalex/arcOS-benchmark-colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zD04nv-w2XzA"
   },
   "source": [
    "## Cell 1: Environment Setup\n",
    "\n",
    "Install dependencies and verify GPU availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1Y0UZMb2XzA",
    "outputId": "3100ab7a-b108-48d0-bf5d-5e3067893de3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "STEP 1: ENVIRONMENT PATH VERIFICATION\n",
      "======================================================================\n",
      "Current kernel executable: /usr/bin/python3\n",
      "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "Site packages: /content\n",
      "✓ UV available: uv 0.9.26\n",
      "\n",
      "======================================================================\n",
      "STEP 2: PACKAGE INSTALLATION\n",
      "======================================================================\n",
      "Installing packages using UV with --python /usr/bin/python3\n",
      "\n",
      "Installing PyTorch with CUDA 11.8 support...\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m3 packages\u001b[0m \u001b[2min 27ms\u001b[0m\u001b[0m\n",
      "\n",
      "Installing additional dependencies...\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 31ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 14ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 11ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 13ms\u001b[0m\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "STEP 3: INSTALLATION VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "Verifying installed packages:\n",
      "\n",
      "✓ torch        v2.8.0+cu128 \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/torch\n",
      "\n",
      "✓ datasets     v4.0.0       \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/datasets\n",
      "\n",
      "✓ networkx     v3.6.1       \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/networkx\n",
      "\n",
      "✓ tqdm         v4.67.3      \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/tqdm\n",
      "\n",
      "✓ faiss        v1.13.2      \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/faiss\n",
      "\n",
      "======================================================================\n",
      "STEP 4: GPU VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "GPU available: False ✗\n",
      "⚠ Warning: No GPU detected.\n",
      "  Go to: Runtime -> Change runtime type -> Select T4 GPU\n",
      "\n",
      "======================================================================\n",
      "ENVIRONMENT SETUP SUMMARY\n",
      "======================================================================\n",
      "Package manager: UV\n",
      "Python executable: /usr/bin/python3\n",
      "All packages verified: ✓ YES\n",
      "GPU available: ✗ NO\n",
      "======================================================================\n",
      "\n",
      "✓ Environment setup complete with full parity!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENVIRONMENT SETUP WITH UV PACKAGE MANAGER\n",
    "# Ensures absolute environment parity between kernel and installed packages\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Colab UV workaround: Clear broken constraint files\n",
    "os.environ[\"UV_CONSTRAINT\"] = \"\"\n",
    "os.environ[\"UV_BUILD_CONSTRAINT\"] = \"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 1: ENVIRONMENT PATH VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Capture current Python executable\n",
    "current_python = sys.executable\n",
    "print(f\"Current kernel executable: {current_python}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Site packages: {sys.path[0] if sys.path else 'N/A'}\")\n",
    "\n",
    "# Check if uv is available\n",
    "def check_uv_available():\n",
    "    \"\"\"Check if uv is installed and accessible.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['uv', '--version'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        return result.returncode == 0\n",
    "    except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "        return False\n",
    "\n",
    "uv_available = check_uv_available()\n",
    "\n",
    "if not uv_available:\n",
    "    print(\"\\n⚠ UV not found. Installing uv package manager...\")\n",
    "    %pip install -q uv\n",
    "    uv_available = check_uv_available()\n",
    "\n",
    "if uv_available:\n",
    "    # Get uv version\n",
    "    uv_version = subprocess.run(\n",
    "        ['uv', '--version'],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    ).stdout.strip()\n",
    "    print(f\"✓ UV available: {uv_version}\")\n",
    "else:\n",
    "    print(\"✗ UV installation failed. Will fall back to pip.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: PACKAGE INSTALLATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define packages to install\n",
    "packages = [\n",
    "    \"datasets\",\n",
    "    \"networkx\",\n",
    "    \"tqdm\",\n",
    "    \"faiss-gpu-cu12\" # Added faiss-gpu\n",
    "]\n",
    "\n",
    "# PyTorch with CUDA support\n",
    "torch_packages = \"torch torchvision torchaudio\"\n",
    "torch_index = \"https://download.pytorch.org/whl/cu118\"\n",
    "\n",
    "if uv_available:\n",
    "    print(f\"Installing packages using UV with --python {current_python}\\n\")\n",
    "\n",
    "    # Install PyTorch with CUDA\n",
    "    print(\"Installing PyTorch with CUDA 11.8 support...\")\n",
    "    !uv pip install --python {current_python} {torch_packages} --index-url {torch_index}\n",
    "\n",
    "    # Install other packages\n",
    "    print(\"\\nInstalling additional dependencies...\")\n",
    "    for package in packages:\n",
    "        !uv pip install --python {current_python} {package}\n",
    "else:\n",
    "    print(\"Falling back to standard pip installation\\n\")\n",
    "\n",
    "    # Install PyTorch with CUDA\n",
    "    print(\"Installing PyTorch with CUDA 11.8 support...\")\n",
    "    %pip install -q {torch_packages} --index-url {torch_index}\n",
    "\n",
    "    # Install other packages\n",
    "    print(\"\\nInstalling additional dependencies...\")\n",
    "    %pip install -q {' '.join(packages)}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: INSTALLATION VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verify installed packages are in the correct location\n",
    "def verify_package_location(package_name):\n",
    "    \"\"\"Verify package is installed in current kernel's site-packages.\"\"\"\n",
    "    try:\n",
    "        module = __import__(package_name)\n",
    "        module_path = Path(module.__file__).parent\n",
    "\n",
    "        # Check if module is in one of sys.path locations\n",
    "        in_sys_path = any(str(module_path).startswith(p) for p in sys.path if p)\n",
    "\n",
    "        # Get version if available\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "\n",
    "        return {\n",
    "            'installed': True,\n",
    "            'version': version,\n",
    "            'location': str(module_path),\n",
    "            'in_sys_path': in_sys_path\n",
    "        }\n",
    "    except ImportError:\n",
    "        return {'installed': False}\n",
    "\n",
    "# Verify key packages\n",
    "verification_packages = ['torch', 'datasets', 'networkx', 'tqdm', 'faiss'] # Added faiss for verification\n",
    "print(\"\\nVerifying installed packages:\\n\")\n",
    "\n",
    "all_verified = True\n",
    "for pkg in verification_packages:\n",
    "    info = verify_package_location(pkg)\n",
    "    if info['installed']:\n",
    "        status = \"✓\" if info['in_sys_path'] else \"⚠\"\n",
    "        print(f\"{status} {pkg:12s} v{info['version']:12s}\")\n",
    "        print(f\"  Location: {info['location']}\")\n",
    "        if not info['in_sys_path']:\n",
    "            print(f\"  WARNING: Not in sys.path!\")\n",
    "            all_verified = False\n",
    "    else:\n",
    "        print(f\"✗ {pkg:12s} NOT INSTALLED\")\n",
    "        all_verified = False\n",
    "    print()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 4: GPU VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import torch\n",
    "gpu_available = torch.cuda.is_available()\n",
    "print(f\"\\nGPU available: {gpu_available} {'✓' if gpu_available else '✗'}\")\n",
    "\n",
    "if gpu_available:\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"⚠ Warning: No GPU detected.\")\n",
    "    print(\"  Go to: Runtime -> Change runtime type -> Select T4 GPU\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENVIRONMENT SETUP SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Package manager: {'UV' if uv_available else 'pip'}\")\n",
    "print(f\"Python executable: {current_python}\")\n",
    "print(f\"All packages verified: {'✓ YES' if all_verified else '✗ NO'}\")\n",
    "print(f\"GPU available: {'✓ YES' if gpu_available else '✗ NO'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if not all_verified:\n",
    "    print(\"\\n⚠ WARNING: Some packages failed verification. Check output above.\")\n",
    "else:\n",
    "    print(\"\\n✓ Environment setup complete with full parity!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dv2OR5W52XzC"
   },
   "source": [
    "## Cell 2: Clean Room Import\n",
    "\n",
    "Purge bytecode caches, scrub `sys.modules`, pin `sys.path`, and verify source file integrity before importing any `src/` modules. Run this cell after every `git pull` or code change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqjQCB9b2XzC",
    "outputId": "d6404854-6845-42e9-c743-a4c88a777257"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "CLEAN ROOM IMPORT\n",
      "======================================================================\n",
      "\n",
      "[1/4] Purging __pycache__ and .pyc files...\n",
      "  Removed 0 __pycache__ dirs, 0 .pyc files\n",
      "\n",
      "[2/4] Scrubbing src.* from sys.modules...\n",
      "  Evicted 0 cached modules: []\n",
      "\n",
      "[3/4] Pinning sys.path priority...\n",
      "  sys.path[0] = /content/arcOS-benchmark-colab\n",
      "\n",
      "[4/4] Verifying source file integrity...\n",
      "  ✓ src/config.py\n",
      "    Modified : 2026-02-15 15:05:28 UTC\n",
      "    MD5      : 65dd4dbe33e660c99769a730c98bbbb4\n",
      "    Size     : 6,168 bytes\n",
      "  ✓ src/retrieval/pcst_solver.py\n",
      "    Modified : 2026-02-15 15:05:28 UTC\n",
      "    MD5      : ab2028fd300e477aefdecbb3e2c8bd9e\n",
      "    Size     : 13,877 bytes\n",
      "  ✓ src/gnn/encoder.py\n",
      "    Modified : 2026-02-15 15:05:28 UTC\n",
      "    MD5      : 14360a080ee2e3b637976156dce7a66f\n",
      "    Size     : 9,077 bytes\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Importing modules (fresh)...\n",
      "✓ All imports successful (clean load)\n",
      "\n",
      "======================================================================\n",
      "CLEAN ROOM COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEAN ROOM IMPORT — guarantees fresh module loading\n",
    "# Run after every git pull / code edit to eliminate stale bytecode & caches\n",
    "# ============================================================================\n",
    "\n",
    "import sys, os, shutil, hashlib, importlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# ── CONFIG ──────────────────────────────────────────────────────────────────\n",
    "REPO_ROOT = Path(\"/content/arcOS-benchmark-colab\")\n",
    "SRC_ROOT  = REPO_ROOT / \"src\"\n",
    "# Files to fingerprint (add any core logic files you want to verify)\n",
    "VERIFY_FILES = [\n",
    "    SRC_ROOT / \"config.py\",\n",
    "    SRC_ROOT / \"retrieval\" / \"pcst_solver.py\",\n",
    "    SRC_ROOT / \"gnn\" / \"encoder.py\",\n",
    "]\n",
    "# Module prefixes to scrub from sys.modules\n",
    "SCRUB_PREFIXES = (\"src\", \"src.\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CLEAN ROOM IMPORT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ── STEP 1: Bytecode Purge ─────────────────────────────────────────────────\n",
    "print(\"\\n[1/4] Purging __pycache__ and .pyc files...\")\n",
    "cache_dirs_removed = 0\n",
    "pyc_files_removed  = 0\n",
    "\n",
    "for cache_dir in SRC_ROOT.rglob(\"__pycache__\"):\n",
    "    shutil.rmtree(cache_dir)\n",
    "    cache_dirs_removed += 1\n",
    "\n",
    "for pyc_file in SRC_ROOT.rglob(\"*.pyc\"):\n",
    "    pyc_file.unlink()\n",
    "    pyc_files_removed += 1\n",
    "\n",
    "print(f\"  Removed {cache_dirs_removed} __pycache__ dirs, {pyc_files_removed} .pyc files\")\n",
    "\n",
    "# ── STEP 2: sys.modules Scrub ──────────────────────────────────────────────\n",
    "print(\"\\n[2/4] Scrubbing src.* from sys.modules...\")\n",
    "stale_keys = [k for k in sys.modules if k.startswith(SCRUB_PREFIXES)]\n",
    "for key in stale_keys:\n",
    "    del sys.modules[key]\n",
    "print(f\"  Evicted {len(stale_keys)} cached modules: {stale_keys[:8]}{'...' if len(stale_keys) > 8 else ''}\")\n",
    "\n",
    "# ── STEP 3: Path Priority ─────────────────────────────────────────────────\n",
    "print(\"\\n[3/4] Pinning sys.path priority...\")\n",
    "repo_str = str(REPO_ROOT)\n",
    "# Remove any existing entries to avoid duplicates\n",
    "sys.path = [p for p in sys.path if p != repo_str]\n",
    "# Insert at position 0 so our src/ wins over any pip-installed version\n",
    "sys.path.insert(0, repo_str)\n",
    "print(f\"  sys.path[0] = {sys.path[0]}\")\n",
    "\n",
    "# ── STEP 4: Source File Validation ─────────────────────────────────────────\n",
    "print(\"\\n[4/4] Verifying source file integrity...\")\n",
    "\n",
    "def file_fingerprint(path: Path) -> dict:\n",
    "    \"\"\"Return last-modified timestamp and MD5 hash for a file.\"\"\"\n",
    "    data = path.read_bytes()\n",
    "    md5  = hashlib.md5(data).hexdigest()\n",
    "    mtime = datetime.fromtimestamp(path.stat().st_mtime, tz=timezone.utc)\n",
    "    return {\"md5\": md5, \"modified\": mtime.strftime(\"%Y-%m-%d %H:%M:%S UTC\"), \"size\": len(data)}\n",
    "\n",
    "for fpath in VERIFY_FILES:\n",
    "    if fpath.exists():\n",
    "        info = file_fingerprint(fpath)\n",
    "        rel  = fpath.relative_to(REPO_ROOT)\n",
    "        print(f\"  ✓ {rel}\")\n",
    "        print(f\"    Modified : {info['modified']}\")\n",
    "        print(f\"    MD5      : {info['md5']}\")\n",
    "        print(f\"    Size     : {info['size']:,} bytes\")\n",
    "    else:\n",
    "        print(f\"  ⚠ {fpath} — NOT FOUND (skipped)\")\n",
    "\n",
    "# ── STEP 5: Fresh Imports ──────────────────────────────────────────────────\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Importing modules (fresh)...\")\n",
    "\n",
    "from src.config import BenchmarkConfig\n",
    "from src.utils.seeds import set_seeds\n",
    "from src.utils.checkpoints import (\n",
    "    ensure_drive_mounted,\n",
    "    checkpoint_exists,\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    "    create_checkpoint_dirs,\n",
    ")\n",
    "from src.data.dataset_loader import RoGWebQSPLoader\n",
    "from src.data.graph_builder import GraphBuilder\n",
    "\n",
    "print(\"✓ All imports successful (clean load)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLEAN ROOM COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lbv4KpD12XzD"
   },
   "source": [
    "## Cell 3: Configuration\n",
    "\n",
    "Initialize benchmark configuration with hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbf7sF7A2XzE",
    "outputId": "f22797f2-3f66-480b-906b-481ac3d0aae1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================================================\n",
      "arcOS Benchmark Configuration\n",
      "============================================================\n",
      "Seed: 42 (deterministic=True)\n",
      "Dataset: rmanluo/RoG-webqsp\n",
      "Drive root: /content/drive/MyDrive/arcOS_benchmark\n",
      "Checkpoint dir: /content/drive/MyDrive/arcOS_benchmark/checkpoints\n",
      "Results dir: /content/drive/MyDrive/arcOS_benchmark/results\n",
      "\n",
      "--- Retrieval ---\n",
      "Embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Top-K entities: 15\n",
      "PCST budget: 70\n",
      "PCST local budget: 300\n",
      "PCST edge cost: 1.0\n",
      "PCST pruning: gw\n",
      "PCST base prize ratio: 1.0\n",
      "\n",
      "--- GNN ---\n",
      "Hidden dim: 256\n",
      "Num layers: 3\n",
      "Num heads: 4\n",
      "Pooling: attention\n",
      "\n",
      "--- LLM ---\n",
      "Model: anthropic/claude-3.5-sonnet\n",
      "Provider: openrouter\n",
      "Temperature: 0.0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize configuration\n",
    "config = BenchmarkConfig(\n",
    "    seed=42,\n",
    "    deterministic=True,\n",
    "    drive_root=\"/content/drive/MyDrive/arcOS_benchmark\",\n",
    ")\n",
    "\n",
    "# Print configuration summary\n",
    "config.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrmwQcua2XzG"
   },
   "source": [
    "## Cell 4: Seed Initialization\n",
    "\n",
    "Set random seeds for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NuvkZMYQ2XzH",
    "outputId": "6e6fc446-3c9c-434b-e1a6-68ecc49cdf04"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ Random seeds set to 42 (deterministic=True)\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds(config.seed, config.deterministic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgEi3ieQ2XzH"
   },
   "source": [
    "## Cell 5: Google Drive Setup\n",
    "\n",
    "Mount Google Drive and create checkpoint/results directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjnHwHNG2XzI",
    "outputId": "75be254d-6193-4d96-feb0-c6ef3102af99"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ Google Drive already mounted at /content/drive\n",
      "✓ Checkpoint directory: /content/drive/MyDrive/arcOS_benchmark/checkpoints\n",
      "✓ Results directory: /content/drive/MyDrive/arcOS_benchmark/results\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "drive_mounted = ensure_drive_mounted()\n",
    "\n",
    "if drive_mounted:\n",
    "    # Create checkpoint and results directories\n",
    "    create_checkpoint_dirs(config.checkpoint_dir, config.results_dir)\n",
    "else:\n",
    "    print(\"⚠ Warning: Drive not mounted. Checkpointing will not work.\")\n",
    "    print(\"  Continuing with local /content/ storage (temporary)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_PN8Rjb2XzI"
   },
   "source": [
    "## Cell 6: Dataset Loading\n",
    "\n",
    "Load RoG-WebQSP dataset from HuggingFace with Drive caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "HKOysb1o2XzJ",
    "outputId": "0d5ba752-70e5-4b93-fc22-4381fa1437a9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ HuggingFace cache directory: /content/drive/MyDrive/arcOS_benchmark/checkpoints/huggingface_cache\n",
      "Loading dataset from checkpoint...\n",
      "✓ Checkpoint loaded: /content/drive/MyDrive/arcOS_benchmark/checkpoints/dataset.pkl (pickle)\n",
      "✓ Dataset loaded from checkpoint.\n",
      "\n",
      "============================================================\n",
      "Dataset Slicing\n",
      "============================================================\n",
      "Original sizes:\n",
      "  Train: 2826\n",
      "  Validation: 246\n",
      "  Test: 1628\n",
      "\n",
      "Sliced sizes:\n",
      "  Train: 900\n",
      "  Validation: 90\n",
      "  Test: 1628\n",
      "\n",
      "✓ Dataset sliced successfully\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Dataset Schema Inspection\n",
      "============================================================\n",
      "Inspecting first split: train\n",
      "\n",
      "Fields:\n",
      "  - id: Value('string')\n",
      "  - question: Value('string')\n",
      "  - answer: List(Value('string'))\n",
      "  - q_entity: List(Value('string'))\n",
      "  - a_entity: List(Value('string'))\n",
      "  - graph: List(List(Value('string')))\n",
      "  - choices: List(Value('null'))\n",
      "\n",
      "✓ All expected fields present\n",
      "\n",
      "Sample Examples (first 1):\n",
      "\n",
      "--- Example 0 ---\n",
      "ID: WebQTrn-0\n",
      "Question: what is the name of justin bieber brother\n",
      "Answer: ['Jaxon Bieber']\n",
      "Question Entity: ['Justin Bieber']\n",
      "Answer Entity: ['Jaxon Bieber']\n",
      "Choices: []\n",
      "Graph: 9088 triples\n",
      "  Sample triple: ['P!nk', 'freebase.valuenotation.is_reviewed', 'Gender']\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Dataset Statistics\n",
      "============================================================\n",
      "\n",
      "--- train ---\n",
      "Total examples: 900\n",
      "Graph size (triples):\n",
      "  - Average: 4251.4\n",
      "  - Min: 68\n",
      "  - Max: 10185\n",
      "\n",
      "--- validation ---\n",
      "Total examples: 90\n",
      "Graph size (triples):\n",
      "  - Average: 4121.7\n",
      "  - Min: 68\n",
      "  - Max: 9496\n",
      "\n",
      "--- test ---\n",
      "Total examples: 1628\n",
      "Graph size (triples):\n",
      "  - Average: 4309.3\n",
      "  - Min: 2\n",
      "  - Max: 10810\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Dataset Split Validation\n",
      "============================================================\n",
      "Train: 900 ✓\n",
      "Validation: 90 ✓\n",
      "Test: 1628 ✓\n",
      "\n",
      "✓ All splits have expected sizes\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataset loader\n",
    "cache_dir = config.checkpoint_dir / \"huggingface_cache\"\n",
    "loader = RoGWebQSPLoader(cache_dir=cache_dir)\n",
    "\n",
    "# Check for cached dataset\n",
    "dataset_checkpoint_path = config.get_checkpoint_path(\"dataset.pkl\")\n",
    "\n",
    "dataset = None # Initialize dataset to None\n",
    "\n",
    "if checkpoint_exists(dataset_checkpoint_path):\n",
    "    print(\"Loading dataset from checkpoint...\")\n",
    "    try:\n",
    "        dataset = load_checkpoint(dataset_checkpoint_path, format=\"pickle\")\n",
    "        print(\"✓ Dataset loaded from checkpoint.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"⚠ Warning: Failed to load dataset from checkpoint due to missing files: {e}\")\n",
    "        print(\"  Falling back to downloading dataset from HuggingFace...\")\n",
    "        # If loading fails, proceed to download\n",
    "        pass # dataset remains None, so the next block will execute\n",
    "\n",
    "if dataset is None: # If dataset was not loaded successfully or checkpoint didn't exist\n",
    "    print(\"Downloading dataset from HuggingFace...\")\n",
    "    dataset = loader.load(dataset_name=config.dataset_name)\n",
    "    save_checkpoint(dataset, dataset_checkpoint_path, format=\"pickle\")\n",
    "    print(\"✓ Dataset downloaded and saved to checkpoint.\")\n",
    "\n",
    "# Slice dataset to desired sizes\n",
    "dataset = loader.slice_dataset(\n",
    "    dataset,\n",
    "    train_size=900,\n",
    "    val_size=90,\n",
    "    test_size=None  # Keep all test examples\n",
    ")\n",
    "\n",
    "# Inspect dataset schema\n",
    "loader.inspect_schema(dataset, num_examples=1)\n",
    "\n",
    "# Compute statistics\n",
    "loader.compute_statistics(dataset)\n",
    "\n",
    "# Validate split counts (updated for sliced dataset)\n",
    "split_valid = loader.validate_split_counts(\n",
    "    dataset,\n",
    "    expected_train=900,\n",
    "    expected_val=90,\n",
    "    expected_test=1628,  # Keep original test size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tpm668x2XzJ"
   },
   "source": [
    "## Cell 7: Graph Construction\n",
    "\n",
    "Build NetworkX graphs from dataset triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "UBzceOT52XzJ",
    "outputId": "41cf1cce-b004-49d3-c3dd-155b0d0d3c21"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ GraphBuilder initialized (directed=True)\n",
      "Loading unified graph from checkpoint...\n",
      "✓ Checkpoint loaded: /content/drive/MyDrive/arcOS_benchmark/checkpoints/unified_graph.pkl (pickle)\n",
      "\n",
      "============================================================\n",
      "Unified Training Graph Information\n",
      "============================================================\n",
      "Nodes: 543170\n",
      "Edges: 1553935\n",
      "Directed: True\n",
      "Density: 0.000005\n",
      "Weakly connected: True\n",
      "\n",
      "Relation Statistics:\n",
      "Unique relations: 4797\n",
      "Top 10 relations:\n",
      "  - common.topic.notable_types: 73649\n",
      "  - freebase.valuenotation.is_reviewed: 39352\n",
      "  - location.location.containedby: 34265\n",
      "  - common.topic.notable_for: 33116\n",
      "  - people.person.profession: 25576\n",
      "  - people.person.gender: 22162\n",
      "  - common.topic.article: 19550\n",
      "  - people.person.nationality: 19116\n",
      "  - common.topic.webpage: 18736\n",
      "  - common.webpage.topic: 18719\n",
      "\n",
      "Degree Statistics:\n",
      "Average in-degree: 2.86\n",
      "Average out-degree: 2.86\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Graph Size Validation\n",
      "============================================================\n",
      "Nodes: 543170 ✓\n",
      "Edges: 1553935 ✓\n",
      "\n",
      "✓ Graph meets size requirements\n",
      "============================================================\n",
      "\n",
      "Building sample per-example graph...\n",
      "\n",
      "============================================================\n",
      "Sample Per-Example Graph Information\n",
      "============================================================\n",
      "Nodes: 1723\n",
      "Edges: 8286\n",
      "Directed: True\n",
      "Density: 0.002793\n",
      "Weakly connected: True\n",
      "\n",
      "Relation Statistics:\n",
      "Unique relations: 320\n",
      "Top 10 relations:\n",
      "  - freebase.valuenotation.is_reviewed: 898\n",
      "  - broadcast.content.artist: 771\n",
      "  - music.artist.genre: 742\n",
      "  - broadcast.artist.content: 631\n",
      "  - people.person.profession: 614\n",
      "  - common.topic.notable_types: 395\n",
      "  - people.person.gender: 208\n",
      "  - people.person.nationality: 179\n",
      "  - broadcast.content.genre: 136\n",
      "  - common.topic.notable_for: 135\n",
      "\n",
      "Degree Statistics:\n",
      "Average in-degree: 4.81\n",
      "Average out-degree: 4.81\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize graph builder\n",
    "graph_builder = GraphBuilder(directed=config.graph_directed)\n",
    "\n",
    "# Check for cached unified graph\n",
    "unified_graph_path = config.get_checkpoint_path(\"unified_graph.pkl\")\n",
    "\n",
    "if checkpoint_exists(unified_graph_path):\n",
    "    print(\"Loading unified graph from checkpoint...\")\n",
    "    unified_graph = load_checkpoint(unified_graph_path, format=\"pickle\")\n",
    "else:\n",
    "    print(\"Building unified graph from training split...\")\n",
    "    unified_graph = graph_builder.build_unified_graph(dataset[\"train\"])\n",
    "    save_checkpoint(unified_graph, unified_graph_path, format=\"pickle\")\n",
    "\n",
    "# Print graph statistics\n",
    "graph_builder.print_graph_info(unified_graph, name=\"Unified Training Graph\")\n",
    "\n",
    "# Validate graph size\n",
    "graph_valid = graph_builder.validate_graph_size(\n",
    "    unified_graph,\n",
    "    min_nodes=config.unified_graph_min_nodes,\n",
    "    min_edges=config.unified_graph_min_edges,\n",
    ")\n",
    "\n",
    "# Build sample per-example graph for demonstration\n",
    "print(\"\\nBuilding sample per-example graph...\")\n",
    "sample_example = dataset[\"train\"][0]\n",
    "sample_graph = graph_builder.build_from_triples(\n",
    "    sample_example[\"graph\"],\n",
    "    graph_id=sample_example[\"id\"]\n",
    ")\n",
    "graph_builder.print_graph_info(sample_graph, name=\"Sample Per-Example Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pHieT482XzJ"
   },
   "source": [
    "## Cell 8: Phase 1 Validation\n",
    "\n",
    "Automated validation of all Phase 1 success criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEm6SVWK2XzK"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Phase 1 Success Criteria Validation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Collect validation results\n",
    "validation_results = {\n",
    "    \"GPU Available\": torch.cuda.is_available(),\n",
    "    \"All Imports Successful\": True,  # If we got here, imports worked\n",
    "    \"Dataset Splits Valid\": split_valid,\n",
    "    \"Unified Graph Size Valid\": graph_valid,\n",
    "}\n",
    "\n",
    "# Test checkpoint round-trip\n",
    "test_checkpoint_path = config.get_checkpoint_path(\"test_roundtrip.pkl\")\n",
    "test_data = {\"test\": \"round-trip\", \"value\": 42}\n",
    "try:\n",
    "    save_checkpoint(test_data, test_checkpoint_path, format=\"pickle\")\n",
    "    loaded_data = load_checkpoint(test_checkpoint_path, format=\"pickle\")\n",
    "    checkpoint_roundtrip_ok = (loaded_data == test_data)\n",
    "    validation_results[\"Checkpoint Round-Trip\"] = checkpoint_roundtrip_ok\n",
    "except Exception as e:\n",
    "    print(f\"Checkpoint round-trip failed: {e}\")\n",
    "    validation_results[\"Checkpoint Round-Trip\"] = False\n",
    "\n",
    "# Print results\n",
    "print(\"\\nValidation Results:\")\n",
    "all_passed = True\n",
    "for criterion, passed in validation_results.items():\n",
    "    status = \"✓\" if passed else \"✗\"\n",
    "    print(f\"  {status} {criterion}\")\n",
    "    if not passed:\n",
    "        all_passed = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_passed:\n",
    "    print(\"✓ PHASE 1 COMPLETE - All criteria passed!\")\n",
    "    print(\"\\nReady to proceed to Phase 2: Retrieval Pipeline\")\n",
    "else:\n",
    "    print(\"✗ PHASE 1 INCOMPLETE - Some criteria failed\")\n",
    "    print(\"\\nPlease review failed criteria above\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nPhase 1 Summary:\")\n",
    "print(f\"  Dataset: {config.dataset_name}\")\n",
    "print(f\"  Training examples: {len(dataset['train'])}\")\n",
    "print(f\"  Validation examples: {len(dataset['validation'])}\")\n",
    "print(f\"  Test examples: {len(dataset['test'])}\")\n",
    "print(f\"  Unified graph nodes: {unified_graph.number_of_nodes()}\")\n",
    "print(f\"  Unified graph edges: {unified_graph.number_of_edges()}\")\n",
    "print(f\"  Checkpoints saved to: {config.checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FN_Yhru52XzK"
   },
   "source": [
    "## Cell 9: Build Retrieval Pipeline\n",
    "\n",
    "Initialize retrieval components (embeddings, FAISS index, PCST solver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BXng-Wzu1U8c",
    "outputId": "21c3466a-6ee0-41f3-ea25-8e04914dbf6d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 82ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install pcst-fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1d27e88c95a543eaa1fca95bba175bc2",
      "9cdbecb3c4cd498781a8bc2aa4908b79",
      "7a9e86028b464db48aaa4ea2f091c73d",
      "c451c251ecb04fe1b9d958356ebd7208",
      "0ef51609179642868ef0bf206e15f4bc",
      "f04f14dfe1934393aa0e0f5a1997d560",
      "07534a33162147a18729b7ba809c6fa0",
      "32373580d4a749fdbb1e883a633c1410",
      "1d5922861d564afc89aedb8c0e4b3820",
      "36c27afb2b514dcc9161f223bfb1a6d1",
      "89ce6627513340fb91b36ab40b89a4b7"
     ]
    },
    "id": "I48MWhc62XzL",
    "outputId": "88e9eee2-ada7-486d-bd8e-59b12a93f68d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================================================\n",
      "PHASE 2: RETRIEVAL PIPELINE\n",
      "============================================================\n",
      "============================================================\n",
      "BUILDING RETRIEVAL PIPELINE\n",
      "============================================================\n",
      "\n",
      "[1/4] Initializing text embedder...\n",
      "⚠ CUDA not available, falling back to CPU for embeddings\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d27e88c95a543eaa1fca95bba175bc2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ Loaded embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "  - Device: cpu\n",
      "  - Embedding dimension: 384\n",
      "\n",
      "[2/4] Loading/computing entity embeddings...\n",
      "Loading cached embeddings from entity_embeddings.pkl\n",
      "✓ Checkpoint loaded: /content/drive/MyDrive/arcOS_benchmark/checkpoints/entity_embeddings.pkl (pickle)\n",
      "✓ Loaded 543170 entity embeddings\n",
      "\n",
      "[3/4] Loading/computing relation embeddings...\n",
      "Loading cached relation embeddings from relation_embeddings.pkl\n",
      "✓ Checkpoint loaded: /content/drive/MyDrive/arcOS_benchmark/checkpoints/relation_embeddings.pkl (pickle)\n",
      "✓ Loaded 4797 relation embeddings\n",
      "\n",
      "[4/4] Loading/building FAISS index...\n",
      "Loading cached FAISS index from faiss_index.bin\n",
      "✓ Loaded FAISS index from /content/drive/MyDrive/arcOS_benchmark/checkpoints/faiss_index.bin\n",
      "  - 543170 entities indexed\n",
      "\n",
      "Initializing PCST solver...\n",
      "✓ PCST solver ready (cost: 1.0, budget: 70, local: 300, pruning: gw, base_prize_ratio: 1.0)\n",
      "\n",
      "============================================================\n",
      "✓ RETRIEVAL PIPELINE READY\n",
      "============================================================\n",
      "\n",
      "✓ Retrieval pipeline initialized\n",
      "  - Entity embeddings: 543170 entities\n",
      "  - Top-K: 15\n",
      "  - PCST budget: 70 nodes\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PHASE 2: RETRIEVAL PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from src.retrieval import Retriever\n",
    "\n",
    "# Build retriever (uses checkpoints if available)\n",
    "retriever = Retriever.build_from_checkpoint_or_new(\n",
    "    config=config,\n",
    "    unified_graph=unified_graph  # From Phase 1 Cell 7\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Retrieval pipeline initialized\")\n",
    "print(f\"  - Entity embeddings: {len(retriever.entity_index)} entities\")\n",
    "print(f\"  - Top-K: {config.top_k_entities}\")\n",
    "print(f\"  - PCST budget: {config.pcst_budget} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VwowPg62XzL"
   },
   "source": [
    "## Cell 10: Retrieval Validation\n",
    "\n",
    "Test retrieval pipeline on 10 validation examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfRB6T_p2XzL",
    "outputId": "2d7d6e7c-32a4-419a-faf7-0d0b8a7cf84e"
   },
   "outputs": [],
   "source": "print(\"\\n\" + \"=\" * 60)\nprint(\"RETRIEVAL VALIDATION (up to 50 examples)\")\nprint(\"=\" * 60)\n\n# Use up to 50 validation examples for statistically meaningful results\nn_val = min(50, len(dataset[\"validation\"]))\nval_examples = list(dataset[\"validation\"].select(range(n_val)))\n\nhit_count = 0\ntotal_time_ms = 0\nsubgraph_sizes = []\n\nfor i, example in enumerate(val_examples):\n    question = example[\"question\"]\n    answer_entities = example.get(\"a_entity\", [])\n    if isinstance(answer_entities, str):\n        answer_entities = [answer_entities]\n\n    # Extract topic entities from dataset\n    q_entities = example.get(\"q_entity\", [])\n    if isinstance(q_entities, str):\n        q_entities = [q_entities]\n\n    # Retrieve subgraph (q_entity used as primary seed when available)\n    result = retriever.retrieve(question, q_entity=q_entities, answer_entities=answer_entities)\n\n    # has_answer is now set on the result by retrieve()\n    hit = result.has_answer\n\n    if hit:\n        hit_count += 1\n\n    total_time_ms += result.retrieval_time_ms\n    subgraph_sizes.append(result.num_nodes)\n\n    # Print example\n    print(f\"\\n[{i+1}/{n_val}] Q: {question[:60]}...\")\n    print(f\"  Topic entities (q_entity): {q_entities}\")\n    print(f\"  Answer entities: {answer_entities}\")\n    print(f\"  Seeds used: {result.seed_entities[:5]}{'...' if len(result.seed_entities) > 5 else ''}\")\n    print(f\"  Subgraph: {result.num_nodes} nodes, {result.num_edges} edges\")\n    print(f\"  Hit: {'✓' if hit else '✗'}\")\n    print(f\"  Time: {result.retrieval_time_ms:.1f}ms\")\n\n# Summary metrics\nhit_rate = hit_count / len(val_examples) * 100\navg_time = total_time_ms / len(val_examples)\navg_size = sum(subgraph_sizes) / len(subgraph_sizes)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"VALIDATION SUMMARY\")\nprint(\"=\" * 60)\nprint(f\"Hit rate: {hit_rate:.1f}% ({hit_count}/{len(val_examples)})\")\nprint(f\"Avg retrieval time: {avg_time:.1f}ms\")\nprint(f\"Avg subgraph size: {avg_size:.1f} nodes\")\nprint(f\"Max subgraph size: {max(subgraph_sizes)} nodes\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju6e-sE22XzM"
   },
   "source": [
    "## Cell 11: Phase 2 Success Criteria\n",
    "\n",
    "Validate Phase 2 completion criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEDJ25h_2XzM"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PHASE 2 SUCCESS CRITERIA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Criterion 1: Retrieval speed < 1 second\n",
    "speed_pass = avg_time < 1000  # ms\n",
    "print(f\"[{'✓' if speed_pass else '✗'}] Retrieval completes in <1 second: {avg_time:.1f}ms\")\n",
    "\n",
    "# Criterion 2: Hit rate > 60%\n",
    "hit_pass = hit_rate >= 60.0\n",
    "print(f\"[{'✓' if hit_pass else '✗'}] Subgraph contains answer entity >60%: {hit_rate:.1f}%\")\n",
    "\n",
    "# Criterion 3: All subgraphs connected\n",
    "all_connected = all(\n",
    "    nx.is_weakly_connected(\n",
    "        retriever.retrieve(\n",
    "            example[\"question\"],\n",
    "            q_entity=example.get(\"q_entity\")\n",
    "        ).subgraph\n",
    "    )\n",
    "    for example in val_examples[:5]  # Check first 5\n",
    ")\n",
    "print(f\"[{'✓' if all_connected else '✗'}] All subgraphs are connected\")\n",
    "\n",
    "# Criterion 4: Subgraph size respects budget\n",
    "size_pass = max(subgraph_sizes) <= config.pcst_budget\n",
    "print(f\"[{'✓' if size_pass else '✗'}] Subgraph size ≤ budget ({max(subgraph_sizes)} ≤ {config.pcst_budget})\")\n",
    "\n",
    "# Overall pass\n",
    "all_pass = speed_pass and hit_pass and all_connected and size_pass\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if all_pass:\n",
    "    print(\"✓ PHASE 2 COMPLETE - All criteria met!\")\n",
    "    print(\"\\nReady to proceed to Phase 3: GNN Encoder\")\n",
    "else:\n",
    "    print(\"⚠ PHASE 2 INCOMPLETE - Review failed criteria above\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdPaAEYiab3A"
   },
   "source": [
    "# Phase 3: GNN Encoder\n",
    "## Cell 12: Build/Load GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "8YgdaqamjdWl"
   },
   "outputs": [],
   "source": [
    "!uv pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbTg--JZkzUx"
   },
   "outputs": [],
   "source": [
    "# Install torch_geometric and its dependencies\n",
    "print(\"Installing torch_geometric...\")\n",
    "!uv pip install torch_geometric torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-2.8.0+cu128.html\n",
    "print(\"✓ torch_geometric installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiad8bLiab3B"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PHASE 3: GNN Encoder\n",
    "# ============================================================\n",
    "\n",
    "print(\"Building GNN Model...\")\n",
    "print(\"This will either:\")\n",
    "print(\"  1. Load pre-trained model from checkpoint, OR\")\n",
    "print(\"  2. Prepare data and train from scratch (~30 min)\")\n",
    "print()\n",
    "\n",
    "from src.gnn import GNNModel\n",
    "\n",
    "# Build GNN model (handles checkpoint loading or training automatically)\n",
    "gnn_model = GNNModel.build_from_checkpoint_or_train(\n",
    "    config=config,\n",
    "    retriever=retriever,\n",
    "    train_data=dataset[\"train\"],\n",
    "    val_data=dataset[\"validation\"],\n",
    "    encoder_type=\"gatv2\",  # or \"graphsage\"\n",
    "    pooling_type=\"attention\",  # or \"mean\", \"max\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GNN Model Ready\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BbYDV0Zab3B"
   },
   "source": [
    "## Cell 13: Test GNN Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J90pfuVTab3B"
   },
   "outputs": [],
   "source": [
    "# Test GNN encoding on a single example\n",
    "print(\"Testing GNN inference on example query...\\n\")\n",
    "\n",
    "test_question = \"Who is Justin Bieber's brother?\"\n",
    "print(f\"Question: {test_question}\")\n",
    "\n",
    "# Retrieve subgraph\n",
    "retrieved = retriever.retrieve(test_question)\n",
    "print(f\"Retrieved subgraph: {retrieved.num_nodes} nodes, {retrieved.num_edges} edges\")\n",
    "\n",
    "# Encode with GNN\n",
    "gnn_output = gnn_model.encode(retrieved, test_question)\n",
    "\n",
    "print(f\"\\nGNN Output:\")\n",
    "print(f\"  Node embeddings shape: {gnn_output.node_embeddings.shape}\")\n",
    "print(f\"  Graph embedding shape: {gnn_output.graph_embedding.shape}\")\n",
    "print(f\"  Attention scores: {len(gnn_output.attention_scores)} nodes\")\n",
    "\n",
    "# Get top attention nodes\n",
    "top_nodes = gnn_model.get_top_attention_nodes(gnn_output, top_k=10)\n",
    "print(f\"\\nTop 10 nodes by attention score:\")\n",
    "for i, (node, score) in enumerate(top_nodes, 1):\n",
    "    print(f\"  {i}. {node}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYEaOgU3ab3B"
   },
   "source": [
    "## Cell 14: Validate GNN Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lXQ_Uzgab3B"
   },
   "outputs": [],
   "source": [
    "# Load training history and display metrics\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_path = config.get_checkpoint_path(\"gnn_training_history.json\")\n",
    "with open(history_path, \"r\") as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PHASE 3 VALIDATION: GNN Metrics\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Best metrics\n",
    "best_val_f1 = max(history[\"val_f1\"])\n",
    "best_val_loss = min(history[\"val_loss\"])\n",
    "final_val_f1 = history[\"val_f1\"][-1]\n",
    "\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"  Epochs trained: {len(history['train_loss'])}\")\n",
    "print(f\"  Best validation F1: {best_val_f1:.3f}\")\n",
    "print(f\"  Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"  Final validation F1: {final_val_f1:.3f}\")\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "axes[0].plot(history[\"val_loss\"], label=\"Val Loss\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Training and Validation Loss\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# F1 curve\n",
    "axes[1].plot(history[\"train_f1\"], label=\"Train F1\")\n",
    "axes[1].plot(history[\"val_f1\"], label=\"Val F1\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"F1 Score\")\n",
    "axes[1].set_title(\"Answer Node Prediction F1\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Success criteria check\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Success Criteria:\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "criteria = [\n",
    "    (\"Validation F1 > 0.5\", best_val_f1 > 0.5, best_val_f1),\n",
    "    (\"Training completed < 30 min\", True, \"N/A\"),  # User observation\n",
    "    (\"No OOM errors\", True, \"N/A\"),  # User observation\n",
    "]\n",
    "\n",
    "for criterion, passed, value in criteria:\n",
    "    status = \"✓ PASS\" if passed else \"✗ FAIL\"\n",
    "    print(f\"{status} - {criterion}: {value}\")\n",
    "\n",
    "if all(c[1] for c in criteria):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUCCESS: Phase 3 Complete\")\n",
    "    print(f\"{'='*60}\")\n",
    "else:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FAILED: Some criteria not met\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V278nVPzab3B"
   },
   "source": [
    "## Cell 15: Visualize Attention on Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0RRpTpHab3B"
   },
   "outputs": [],
   "source": [
    "# Visualize GNN attention on a subgraph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def visualize_gnn_attention(\n",
    "    subgraph: nx.DiGraph,\n",
    "    attention_scores: dict,\n",
    "    answer_entities: list,\n",
    "    question: str,\n",
    "    top_k: int = 20,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize GNN attention on a subgraph.\n",
    "\n",
    "    Args:\n",
    "        subgraph: NetworkX DiGraph\n",
    "        attention_scores: Dict[node_name, float]\n",
    "        answer_entities: List of ground truth answer entities\n",
    "        question: Question text\n",
    "        top_k: Show only top-K nodes by attention\n",
    "    \"\"\"\n",
    "    # Get top-K nodes by attention\n",
    "    sorted_nodes = sorted(\n",
    "        attention_scores.items(), key=lambda x: x[1], reverse=True\n",
    "    )[:top_k]\n",
    "    top_nodes = [node for node, _ in sorted_nodes]\n",
    "\n",
    "    # Create subgraph with only top nodes\n",
    "    G_viz = subgraph.subgraph(top_nodes).copy()\n",
    "\n",
    "    # Node colors (red = answer, blue = high attention, gray = low attention)\n",
    "    node_colors = []\n",
    "    for node in G_viz.nodes():\n",
    "        if node in answer_entities:\n",
    "            node_colors.append(\"red\")\n",
    "        else:\n",
    "            # Scale by attention (darker = higher attention)\n",
    "            attn = attention_scores.get(node, 0.0)\n",
    "            intensity = min(attn * 10, 1.0)  # Scale for visibility\n",
    "            node_colors.append((0.2, 0.4, 0.8, 0.3 + 0.7 * intensity))\n",
    "\n",
    "    # Node sizes proportional to attention\n",
    "    node_sizes = [\n",
    "        300 + 2000 * attention_scores.get(node, 0.0) for node in G_viz.nodes()\n",
    "    ]\n",
    "\n",
    "    # Layout\n",
    "    pos = nx.spring_layout(G_viz, k=0.5, iterations=50, seed=42)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    plt.title(f\"GNN Attention Visualization\\nQ: {question}\", fontsize=12)\n",
    "\n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(\n",
    "        G_viz, pos, alpha=0.3, arrows=True, arrowsize=10, width=1.0\n",
    "    )\n",
    "\n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(\n",
    "        G_viz, pos, node_color=node_colors, node_size=node_sizes, alpha=0.9\n",
    "    )\n",
    "\n",
    "    # Draw labels (only for top 10)\n",
    "    labels = {node: node[:20] for node in list(G_viz.nodes())[:10]}\n",
    "    nx.draw_networkx_labels(G_viz, pos, labels, font_size=8)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print attention scores\n",
    "    print(\"Top 10 attention scores:\")\n",
    "    for i, (node, score) in enumerate(sorted_nodes[:10], 1):\n",
    "        is_answer = \"✓ ANSWER\" if node in answer_entities else \"\"\n",
    "        print(f\"  {i}. {node[:30]}: {score:.4f} {is_answer}\")\n",
    "\n",
    "\n",
    "# Test visualization\n",
    "test_question = \"Who is Barack Obama's spouse?\"\n",
    "test_answer = [\"Michelle Obama\", \"m.025s5v9\"]  # Freebase ID\n",
    "\n",
    "retrieved = retriever.retrieve(test_question)\n",
    "gnn_output = gnn_model.encode(retrieved, test_question)\n",
    "\n",
    "visualize_gnn_attention(\n",
    "    subgraph=retrieved.subgraph,\n",
    "    attention_scores=gnn_output.attention_scores,\n",
    "    answer_entities=test_answer,\n",
    "    question=test_question,\n",
    "    top_k=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uV1qeDzzab3C"
   },
   "source": [
    "## Cell 16: Memory Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URJaPvgLab3C"
   },
   "outputs": [],
   "source": [
    "# Check GPU memory usage\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Memory Summary:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "    print(f\"  Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "    print(f\"  Max allocated: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "    # Verify no memory leak\n",
    "    assert torch.cuda.memory_allocated() / 1e9 < 14.0, \"Memory leak detected!\"\n",
    "    print(\"\\n✓ Memory usage within acceptable range\")\n",
    "else:\n",
    "    print(\"GPU not available\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1d27e88c95a543eaa1fca95bba175bc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9cdbecb3c4cd498781a8bc2aa4908b79",
       "IPY_MODEL_7a9e86028b464db48aaa4ea2f091c73d",
       "IPY_MODEL_c451c251ecb04fe1b9d958356ebd7208"
      ],
      "layout": "IPY_MODEL_0ef51609179642868ef0bf206e15f4bc"
     }
    },
    "9cdbecb3c4cd498781a8bc2aa4908b79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f04f14dfe1934393aa0e0f5a1997d560",
      "placeholder": "​",
      "style": "IPY_MODEL_07534a33162147a18729b7ba809c6fa0",
      "value": "Loading weights: 100%"
     }
    },
    "7a9e86028b464db48aaa4ea2f091c73d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32373580d4a749fdbb1e883a633c1410",
      "max": 103,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d5922861d564afc89aedb8c0e4b3820",
      "value": 103
     }
    },
    "c451c251ecb04fe1b9d958356ebd7208": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36c27afb2b514dcc9161f223bfb1a6d1",
      "placeholder": "​",
      "style": "IPY_MODEL_89ce6627513340fb91b36ab40b89a4b7",
      "value": " 103/103 [00:00&lt;00:00, 513.95it/s, Materializing param=pooler.dense.weight]"
     }
    },
    "0ef51609179642868ef0bf206e15f4bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f04f14dfe1934393aa0e0f5a1997d560": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07534a33162147a18729b7ba809c6fa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32373580d4a749fdbb1e883a633c1410": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d5922861d564afc89aedb8c0e4b3820": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "36c27afb2b514dcc9161f223bfb1a6d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89ce6627513340fb91b36ab40b89a4b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}