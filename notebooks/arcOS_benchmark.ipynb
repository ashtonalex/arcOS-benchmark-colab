{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQmG_saT2Xy9"
   },
   "source": [
    "# arcOS Benchmark - Causal QA with GNN + LLM\n",
    "\n",
    "**Phase 1: Environment & Data Foundation**\n",
    "\n",
    "This notebook implements the complete arcOS benchmark pipeline:\n",
    "- Graph Neural Network structural reasoning over knowledge graphs\n",
    "- LLM text generation with graph-guided prompts\n",
    "- Evaluation on RoG-WebQSP question answering dataset\n",
    "\n",
    "**Requirements:**\n",
    "- Google Colab with GPU runtime (T4 or better)\n",
    "- Google Drive mounted for checkpointing\n",
    "- ~10GB free space on Drive\n",
    "\n",
    "**Architecture:**\n",
    "- Dataset: RoG-WebQSP (4,706 QA pairs with Freebase subgraphs)\n",
    "- Graph DB: NetworkX in-memory\n",
    "- GNN: Graph Attention Network (GATv2)\n",
    "- LLM: OpenRouter API (Claude 3.5 Sonnet)\n",
    "- Verbalization: Hard prompts (text-based, not soft embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eazp1RCB1U8W"
   },
   "source": [
    "## Cell 0: Cloning Repository\n",
    "Update notebook with latest updates from GitHub repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Wsy7Km_P1U8X",
    "outputId": "ae37e605-33b3-41fb-c701-8adcf4f64072",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n",
      "Cloning into 'arcOS-benchmark-colab'...\n",
      "remote: Enumerating objects: 236, done.\u001b[K\n",
      "remote: Counting objects: 100% (236/236), done.\u001b[K\n",
      "remote: Compressing objects: 100% (148/148), done.\u001b[K\n",
      "remote: Total 236 (delta 125), reused 183 (delta 75), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (236/236), 229.72 KiB | 4.42 MiB/s, done.\n",
      "Resolving deltas: 100% (125/125), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure we are in a safe directory before operations\n",
    "%cd /content\n",
    "\n",
    "# Remove existing directory if it exists, then clone fresh\n",
    "!rm -rf arcOS-benchmark-colab\n",
    "!git clone https://github.com/ashtonalex/arcOS-benchmark-colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zD04nv-w2XzA"
   },
   "source": [
    "## Cell 1: Environment Setup\n",
    "\n",
    "Install dependencies and verify GPU availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K1Y0UZMb2XzA",
    "outputId": "3100ab7a-b108-48d0-bf5d-5e3067893de3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "STEP 1: ENVIRONMENT PATH VERIFICATION\n",
      "======================================================================\n",
      "Current kernel executable: /usr/bin/python3\n",
      "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "Site packages: /content\n",
      "✓ UV available: uv 0.9.26\n",
      "\n",
      "======================================================================\n",
      "STEP 2: PACKAGE INSTALLATION\n",
      "======================================================================\n",
      "Installing packages using UV with --python /usr/bin/python3\n",
      "\n",
      "Installing PyTorch with CUDA 11.8 support...\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m3 packages\u001b[0m \u001b[2min 27ms\u001b[0m\u001b[0m\n",
      "\n",
      "Installing additional dependencies...\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 31ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 14ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 11ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 13ms\u001b[0m\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "STEP 3: INSTALLATION VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "Verifying installed packages:\n",
      "\n",
      "✓ torch        v2.8.0+cu128 \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/torch\n",
      "\n",
      "✓ datasets     v4.0.0       \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/datasets\n",
      "\n",
      "✓ networkx     v3.6.1       \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/networkx\n",
      "\n",
      "✓ tqdm         v4.67.3      \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/tqdm\n",
      "\n",
      "✓ faiss        v1.13.2      \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/faiss\n",
      "\n",
      "======================================================================\n",
      "STEP 4: GPU VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "GPU available: False ✗\n",
      "⚠ Warning: No GPU detected.\n",
      "  Go to: Runtime -> Change runtime type -> Select T4 GPU\n",
      "\n",
      "======================================================================\n",
      "ENVIRONMENT SETUP SUMMARY\n",
      "======================================================================\n",
      "Package manager: UV\n",
      "Python executable: /usr/bin/python3\n",
      "All packages verified: ✓ YES\n",
      "GPU available: ✗ NO\n",
      "======================================================================\n",
      "\n",
      "✓ Environment setup complete with full parity!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENVIRONMENT SETUP WITH UV PACKAGE MANAGER\n",
    "# Ensures absolute environment parity between kernel and installed packages\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Colab UV workaround: Clear broken constraint files\n",
    "os.environ[\"UV_CONSTRAINT\"] = \"\"\n",
    "os.environ[\"UV_BUILD_CONSTRAINT\"] = \"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 1: ENVIRONMENT PATH VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Capture current Python executable\n",
    "current_python = sys.executable\n",
    "print(f\"Current kernel executable: {current_python}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Site packages: {sys.path[0] if sys.path else 'N/A'}\")\n",
    "\n",
    "# Check if uv is available\n",
    "def check_uv_available():\n",
    "    \"\"\"Check if uv is installed and accessible.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['uv', '--version'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        return result.returncode == 0\n",
    "    except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "        return False\n",
    "\n",
    "uv_available = check_uv_available()\n",
    "\n",
    "if not uv_available:\n",
    "    print(\"\\n⚠ UV not found. Installing uv package manager...\")\n",
    "    %pip install -q uv\n",
    "    uv_available = check_uv_available()\n",
    "\n",
    "if uv_available:\n",
    "    # Get uv version\n",
    "    uv_version = subprocess.run(\n",
    "        ['uv', '--version'],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    ).stdout.strip()\n",
    "    print(f\"✓ UV available: {uv_version}\")\n",
    "else:\n",
    "    print(\"✗ UV installation failed. Will fall back to pip.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: PACKAGE INSTALLATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define packages to install\n",
    "packages = [\n",
    "    \"datasets\",\n",
    "    \"networkx\",\n",
    "    \"tqdm\",\n",
    "    \"faiss-gpu-cu12\" # Added faiss-gpu\n",
    "]\n",
    "\n",
    "# PyTorch with CUDA support\n",
    "torch_packages = \"torch torchvision torchaudio\"\n",
    "torch_index = \"https://download.pytorch.org/whl/cu118\"\n",
    "\n",
    "if uv_available:\n",
    "    print(f\"Installing packages using UV with --python {current_python}\\n\")\n",
    "\n",
    "    # Install PyTorch with CUDA\n",
    "    print(\"Installing PyTorch with CUDA 11.8 support...\")\n",
    "    !uv pip install --python {current_python} {torch_packages} --index-url {torch_index}\n",
    "\n",
    "    # Install other packages\n",
    "    print(\"\\nInstalling additional dependencies...\")\n",
    "    for package in packages:\n",
    "        !uv pip install --python {current_python} {package}\n",
    "else:\n",
    "    print(\"Falling back to standard pip installation\\n\")\n",
    "\n",
    "    # Install PyTorch with CUDA\n",
    "    print(\"Installing PyTorch with CUDA 11.8 support...\")\n",
    "    %pip install -q {torch_packages} --index-url {torch_index}\n",
    "\n",
    "    # Install other packages\n",
    "    print(\"\\nInstalling additional dependencies...\")\n",
    "    %pip install -q {' '.join(packages)}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: INSTALLATION VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verify installed packages are in the correct location\n",
    "def verify_package_location(package_name):\n",
    "    \"\"\"Verify package is installed in current kernel's site-packages.\"\"\"\n",
    "    try:\n",
    "        module = __import__(package_name)\n",
    "        module_path = Path(module.__file__).parent\n",
    "\n",
    "        # Check if module is in one of sys.path locations\n",
    "        in_sys_path = any(str(module_path).startswith(p) for p in sys.path if p)\n",
    "\n",
    "        # Get version if available\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "\n",
    "        return {\n",
    "            'installed': True,\n",
    "            'version': version,\n",
    "            'location': str(module_path),\n",
    "            'in_sys_path': in_sys_path\n",
    "        }\n",
    "    except ImportError:\n",
    "        return {'installed': False}\n",
    "\n",
    "# Verify key packages\n",
    "verification_packages = ['torch', 'datasets', 'networkx', 'tqdm', 'faiss'] # Added faiss for verification\n",
    "print(\"\\nVerifying installed packages:\\n\")\n",
    "\n",
    "all_verified = True\n",
    "for pkg in verification_packages:\n",
    "    info = verify_package_location(pkg)\n",
    "    if info['installed']:\n",
    "        status = \"✓\" if info['in_sys_path'] else \"⚠\"\n",
    "        print(f\"{status} {pkg:12s} v{info['version']:12s}\")\n",
    "        print(f\"  Location: {info['location']}\")\n",
    "        if not info['in_sys_path']:\n",
    "            print(f\"  WARNING: Not in sys.path!\")\n",
    "            all_verified = False\n",
    "    else:\n",
    "        print(f\"✗ {pkg:12s} NOT INSTALLED\")\n",
    "        all_verified = False\n",
    "    print()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 4: GPU VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import torch\n",
    "gpu_available = torch.cuda.is_available()\n",
    "print(f\"\\nGPU available: {gpu_available} {'✓' if gpu_available else '✗'}\")\n",
    "\n",
    "if gpu_available:\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"⚠ Warning: No GPU detected.\")\n",
    "    print(\"  Go to: Runtime -> Change runtime type -> Select T4 GPU\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENVIRONMENT SETUP SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Package manager: {'UV' if uv_available else 'pip'}\")\n",
    "print(f\"Python executable: {current_python}\")\n",
    "print(f\"All packages verified: {'✓ YES' if all_verified else '✗ NO'}\")\n",
    "print(f\"GPU available: {'✓ YES' if gpu_available else '✗ NO'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if not all_verified:\n",
    "    print(\"\\n⚠ WARNING: Some packages failed verification. Check output above.\")\n",
    "else:\n",
    "    print(\"\\n✓ Environment setup complete with full parity!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dv2OR5W52XzC"
   },
   "source": [
    "## Cell 2: Clean Room Import\n",
    "\n",
    "Purge bytecode caches, scrub `sys.modules`, pin `sys.path`, and verify source file integrity before importing any `src/` modules. Run this cell after every `git pull` or code change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqjQCB9b2XzC",
    "outputId": "d6404854-6845-42e9-c743-a4c88a777257"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================================================================\n",
      "CLEAN ROOM IMPORT\n",
      "======================================================================\n",
      "\n",
      "[1/4] Purging __pycache__ and .pyc files...\n",
      "  Removed 0 __pycache__ dirs, 0 .pyc files\n",
      "\n",
      "[2/4] Scrubbing src.* from sys.modules...\n",
      "  Evicted 0 cached modules: []\n",
      "\n",
      "[3/4] Pinning sys.path priority...\n",
      "  sys.path[0] = /content/arcOS-benchmark-colab\n",
      "\n",
      "[4/4] Verifying source file integrity...\n",
      "  ✓ src/config.py\n",
      "    Modified : 2026-02-15 15:05:28 UTC\n",
      "    MD5      : 65dd4dbe33e660c99769a730c98bbbb4\n",
      "    Size     : 6,168 bytes\n",
      "  ✓ src/retrieval/pcst_solver.py\n",
      "    Modified : 2026-02-15 15:05:28 UTC\n",
      "    MD5      : ab2028fd300e477aefdecbb3e2c8bd9e\n",
      "    Size     : 13,877 bytes\n",
      "  ✓ src/gnn/encoder.py\n",
      "    Modified : 2026-02-15 15:05:28 UTC\n",
      "    MD5      : 14360a080ee2e3b637976156dce7a66f\n",
      "    Size     : 9,077 bytes\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Importing modules (fresh)...\n",
      "✓ All imports successful (clean load)\n",
      "\n",
      "======================================================================\n",
      "CLEAN ROOM COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CLEAN ROOM IMPORT — guarantees fresh module loading\n",
    "# Run after every git pull / code edit to eliminate stale bytecode & caches\n",
    "# ============================================================================\n",
    "\n",
    "import sys, os, shutil, hashlib, importlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# ── CONFIG ──────────────────────────────────────────────────────────────────\n",
    "REPO_ROOT = Path(\"/content/arcOS-benchmark-colab\")\n",
    "SRC_ROOT  = REPO_ROOT / \"src\"\n",
    "# Files to fingerprint (add any core logic files you want to verify)\n",
    "VERIFY_FILES = [\n",
    "    SRC_ROOT / \"config.py\",\n",
    "    SRC_ROOT / \"retrieval\" / \"pcst_solver.py\",\n",
    "    SRC_ROOT / \"gnn\" / \"encoder.py\",\n",
    "]\n",
    "# Module prefixes to scrub from sys.modules\n",
    "SCRUB_PREFIXES = (\"src\", \"src.\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CLEAN ROOM IMPORT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ── STEP 1: Bytecode Purge ─────────────────────────────────────────────────\n",
    "print(\"\\n[1/4] Purging __pycache__ and .pyc files...\")\n",
    "cache_dirs_removed = 0\n",
    "pyc_files_removed  = 0\n",
    "\n",
    "for cache_dir in SRC_ROOT.rglob(\"__pycache__\"):\n",
    "    shutil.rmtree(cache_dir)\n",
    "    cache_dirs_removed += 1\n",
    "\n",
    "for pyc_file in SRC_ROOT.rglob(\"*.pyc\"):\n",
    "    pyc_file.unlink()\n",
    "    pyc_files_removed += 1\n",
    "\n",
    "print(f\"  Removed {cache_dirs_removed} __pycache__ dirs, {pyc_files_removed} .pyc files\")\n",
    "\n",
    "# ── STEP 2: sys.modules Scrub ──────────────────────────────────────────────\n",
    "print(\"\\n[2/4] Scrubbing src.* from sys.modules...\")\n",
    "stale_keys = [k for k in sys.modules if k.startswith(SCRUB_PREFIXES)]\n",
    "for key in stale_keys:\n",
    "    del sys.modules[key]\n",
    "print(f\"  Evicted {len(stale_keys)} cached modules: {stale_keys[:8]}{'...' if len(stale_keys) > 8 else ''}\")\n",
    "\n",
    "# ── STEP 3: Path Priority ─────────────────────────────────────────────────\n",
    "print(\"\\n[3/4] Pinning sys.path priority...\")\n",
    "repo_str = str(REPO_ROOT)\n",
    "# Remove any existing entries to avoid duplicates\n",
    "sys.path = [p for p in sys.path if p != repo_str]\n",
    "# Insert at position 0 so our src/ wins over any pip-installed version\n",
    "sys.path.insert(0, repo_str)\n",
    "print(f\"  sys.path[0] = {sys.path[0]}\")\n",
    "\n",
    "# ── STEP 4: Source File Validation ─────────────────────────────────────────\n",
    "print(\"\\n[4/4] Verifying source file integrity...\")\n",
    "\n",
    "def file_fingerprint(path: Path) -> dict:\n",
    "    \"\"\"Return last-modified timestamp and MD5 hash for a file.\"\"\"\n",
    "    data = path.read_bytes()\n",
    "    md5  = hashlib.md5(data).hexdigest()\n",
    "    mtime = datetime.fromtimestamp(path.stat().st_mtime, tz=timezone.utc)\n",
    "    return {\"md5\": md5, \"modified\": mtime.strftime(\"%Y-%m-%d %H:%M:%S UTC\"), \"size\": len(data)}\n",
    "\n",
    "for fpath in VERIFY_FILES:\n",
    "    if fpath.exists():\n",
    "        info = file_fingerprint(fpath)\n",
    "        rel  = fpath.relative_to(REPO_ROOT)\n",
    "        print(f\"  ✓ {rel}\")\n",
    "        print(f\"    Modified : {info['modified']}\")\n",
    "        print(f\"    MD5      : {info['md5']}\")\n",
    "        print(f\"    Size     : {info['size']:,} bytes\")\n",
    "    else:\n",
    "        print(f\"  ⚠ {fpath} — NOT FOUND (skipped)\")\n",
    "\n",
    "# ── STEP 5: Fresh Imports ──────────────────────────────────────────────────\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Importing modules (fresh)...\")\n",
    "\n",
    "from src.config import BenchmarkConfig\n",
    "from src.utils.seeds import set_seeds\n",
    "from src.utils.checkpoints import (\n",
    "    ensure_drive_mounted,\n",
    "    checkpoint_exists,\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    "    create_checkpoint_dirs,\n",
    ")\n",
    "from src.data.dataset_loader import RoGWebQSPLoader\n",
    "from src.data.graph_builder import GraphBuilder\n",
    "\n",
    "print(\"✓ All imports successful (clean load)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLEAN ROOM COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lbv4KpD12XzD"
   },
   "source": [
    "## Cell 3: Configuration\n",
    "\n",
    "Initialize benchmark configuration with hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbf7sF7A2XzE",
    "outputId": "f22797f2-3f66-480b-906b-481ac3d0aae1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================================================\n",
      "arcOS Benchmark Configuration\n",
      "============================================================\n",
      "Seed: 42 (deterministic=True)\n",
      "Dataset: rmanluo/RoG-webqsp\n",
      "Drive root: /content/drive/MyDrive/arcOS_benchmark\n",
      "Checkpoint dir: /content/drive/MyDrive/arcOS_benchmark/checkpoints\n",
      "Results dir: /content/drive/MyDrive/arcOS_benchmark/results\n",
      "\n",
      "--- Retrieval ---\n",
      "Embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Top-K entities: 15\n",
      "PCST budget: 70\n",
      "PCST local budget: 300\n",
      "PCST edge cost: 1.0\n",
      "PCST pruning: gw\n",
      "PCST base prize ratio: 1.0\n",
      "\n",
      "--- GNN ---\n",
      "Hidden dim: 256\n",
      "Num layers: 3\n",
      "Num heads: 4\n",
      "Pooling: attention\n",
      "\n",
      "--- LLM ---\n",
      "Model: anthropic/claude-3.5-sonnet\n",
      "Provider: openrouter\n",
      "Temperature: 0.0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize configuration\n",
    "config = BenchmarkConfig(\n",
    "    seed=42,\n",
    "    deterministic=True,\n",
    "    drive_root=\"/content/drive/MyDrive/arcOS_benchmark\",\n",
    ")\n",
    "\n",
    "# Print configuration summary\n",
    "config.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrmwQcua2XzG"
   },
   "source": [
    "## Cell 4: Seed Initialization\n",
    "\n",
    "Set random seeds for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NuvkZMYQ2XzH",
    "outputId": "6e6fc446-3c9c-434b-e1a6-68ecc49cdf04"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ Random seeds set to 42 (deterministic=True)\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds(config.seed, config.deterministic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgEi3ieQ2XzH"
   },
   "source": [
    "## Cell 5: Google Drive Setup\n",
    "\n",
    "Mount Google Drive and create checkpoint/results directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjnHwHNG2XzI",
    "outputId": "75be254d-6193-4d96-feb0-c6ef3102af99"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ Google Drive already mounted at /content/drive\n",
      "✓ Checkpoint directory: /content/drive/MyDrive/arcOS_benchmark/checkpoints\n",
      "✓ Results directory: /content/drive/MyDrive/arcOS_benchmark/results\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "drive_mounted = ensure_drive_mounted()\n",
    "\n",
    "if drive_mounted:\n",
    "    # Create checkpoint and results directories\n",
    "    create_checkpoint_dirs(config.checkpoint_dir, config.results_dir)\n",
    "else:\n",
    "    print(\"⚠ Warning: Drive not mounted. Checkpointing will not work.\")\n",
    "    print(\"  Continuing with local /content/ storage (temporary)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_PN8Rjb2XzI"
   },
   "source": [
    "## Cell 6: Dataset Loading\n",
    "\n",
    "Load RoG-WebQSP dataset from HuggingFace with Drive caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "HKOysb1o2XzJ",
    "outputId": "0d5ba752-70e5-4b93-fc22-4381fa1437a9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ HuggingFace cache directory: /content/drive/MyDrive/arcOS_benchmark/checkpoints/huggingface_cache\n",
      "Loading dataset from checkpoint...\n",
      "✓ Checkpoint loaded: /content/drive/MyDrive/arcOS_benchmark/checkpoints/dataset.pkl (pickle)\n",
      "✓ Dataset loaded from checkpoint.\n",
      "\n",
      "============================================================\n",
      "Dataset Slicing\n",
      "============================================================\n",
      "Original sizes:\n",
      "  Train: 2826\n",
      "  Validation: 246\n",
      "  Test: 1628\n",
      "\n",
      "Sliced sizes:\n",
      "  Train: 900\n",
      "  Validation: 90\n",
      "  Test: 1628\n",
      "\n",
      "✓ Dataset sliced successfully\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Dataset Schema Inspection\n",
      "============================================================\n",
      "Inspecting first split: train\n",
      "\n",
      "Fields:\n",
      "  - id: Value('string')\n",
      "  - question: Value('string')\n",
      "  - answer: List(Value('string'))\n",
      "  - q_entity: List(Value('string'))\n",
      "  - a_entity: List(Value('string'))\n",
      "  - graph: List(List(Value('string')))\n",
      "  - choices: List(Value('null'))\n",
      "\n",
      "✓ All expected fields present\n",
      "\n",
      "Sample Examples (first 1):\n",
      "\n",
      "--- Example 0 ---\n",
      "ID: WebQTrn-0\n",
      "Question: what is the name of justin bieber brother\n",
      "Answer: ['Jaxon Bieber']\n",
      "Question Entity: ['Justin Bieber']\n",
      "Answer Entity: ['Jaxon Bieber']\n",
      "Choices: []\n",
      "Graph: 9088 triples\n",
      "  Sample triple: ['P!nk', 'freebase.valuenotation.is_reviewed', 'Gender']\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Dataset Statistics\n",
      "============================================================\n",
      "\n",
      "--- train ---\n",
      "Total examples: 900\n",
      "Graph size (triples):\n",
      "  - Average: 4251.4\n",
      "  - Min: 68\n",
      "  - Max: 10185\n",
      "\n",
      "--- validation ---\n",
      "Total examples: 90\n",
      "Graph size (triples):\n",
      "  - Average: 4121.7\n",
      "  - Min: 68\n",
      "  - Max: 9496\n",
      "\n",
      "--- test ---\n",
      "Total examples: 1628\n",
      "Graph size (triples):\n",
      "  - Average: 4309.3\n",
      "  - Min: 2\n",
      "  - Max: 10810\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Dataset Split Validation\n",
      "============================================================\n",
      "Train: 900 ✓\n",
      "Validation: 90 ✓\n",
      "Test: 1628 ✓\n",
      "\n",
      "✓ All splits have expected sizes\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataset loader\n",
    "cache_dir = config.checkpoint_dir / \"huggingface_cache\"\n",
    "loader = RoGWebQSPLoader(cache_dir=cache_dir)\n",
    "\n",
    "# Check for cached dataset\n",
    "dataset_checkpoint_path = config.get_checkpoint_path(\"dataset.pkl\")\n",
    "\n",
    "dataset = None # Initialize dataset to None\n",
    "\n",
    "if checkpoint_exists(dataset_checkpoint_path):\n",
    "    print(\"Loading dataset from checkpoint...\")\n",
    "    try:\n",
    "        dataset = load_checkpoint(dataset_checkpoint_path, format=\"pickle\")\n",
    "        print(\"✓ Dataset loaded from checkpoint.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"⚠ Warning: Failed to load dataset from checkpoint due to missing files: {e}\")\n",
    "        print(\"  Falling back to downloading dataset from HuggingFace...\")\n",
    "        # If loading fails, proceed to download\n",
    "        pass # dataset remains None, so the next block will execute\n",
    "\n",
    "if dataset is None: # If dataset was not loaded successfully or checkpoint didn't exist\n",
    "    print(\"Downloading dataset from HuggingFace...\")\n",
    "    dataset = loader.load(dataset_name=config.dataset_name)\n",
    "    save_checkpoint(dataset, dataset_checkpoint_path, format=\"pickle\")\n",
    "    print(\"✓ Dataset downloaded and saved to checkpoint.\")\n",
    "\n",
    "# Slice dataset to desired sizes\n",
    "dataset = loader.slice_dataset(\n",
    "    dataset,\n",
    "    train_size=900,\n",
    "    val_size=90,\n",
    "    test_size=None  # Keep all test examples\n",
    ")\n",
    "\n",
    "# Inspect dataset schema\n",
    "loader.inspect_schema(dataset, num_examples=1)\n",
    "\n",
    "# Compute statistics\n",
    "loader.compute_statistics(dataset)\n",
    "\n",
    "# Validate split counts (updated for sliced dataset)\n",
    "split_valid = loader.validate_split_counts(\n",
    "    dataset,\n",
    "    expected_train=900,\n",
    "    expected_val=90,\n",
    "    expected_test=1628,  # Keep original test size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# DATA STRUCTURE ANALYSIS — Inspect first 3 rows in detail\n# Understand entity naming, triple structure, and relation patterns\n# before building the graph and embeddings\n# ============================================================================\n\nimport json\nfrom collections import Counter\n\nprint(\"=\" * 70)\nprint(\"DATA STRUCTURE ANALYSIS — First 3 examples\")\nprint(\"=\" * 70)\n\nfor i in range(3):\n    ex = dataset[\"train\"][i]\n    print(f\"\\n{'─' * 70}\")\n    print(f\"EXAMPLE {i}: {ex['id']}\")\n    print(f\"{'─' * 70}\")\n    print(f\"  Question:  {ex['question']}\")\n    print(f\"  Answer:    {ex['answer']}\")\n    print(f\"  q_entity:  {ex['q_entity']}  (type: {type(ex['q_entity']).__name__})\")\n    print(f\"  a_entity:  {ex['a_entity']}  (type: {type(ex['a_entity']).__name__})\")\n    print(f\"  Graph:     {len(ex['graph'])} triples\")\n\n    triples = ex['graph']\n\n    # Collect all unique entities and relations\n    subjects = set()\n    objects_ = set()\n    relations = []\n    for t in triples:\n        subjects.add(t[0])\n        objects_.add(t[2])\n        relations.append(t[1])\n\n    all_entities = subjects | objects_\n    rel_counts = Counter(relations)\n\n    print(f\"\\n  Unique subjects:  {len(subjects)}\")\n    print(f\"  Unique objects:   {len(objects_)}\")\n    print(f\"  Unique entities:  {len(all_entities)}\")\n    print(f\"  Unique relations: {len(set(relations))}\")\n\n    # Show first 10 triples\n    print(f\"\\n  First 10 triples:\")\n    for j, t in enumerate(triples[:10]):\n        print(f\"    [{j}] {t[0]!r}  --({t[1]})-->  {t[2]!r}\")\n\n    # Show last 5 triples (may reveal different patterns)\n    print(f\"\\n  Last 5 triples:\")\n    for j, t in enumerate(triples[-5:]):\n        print(f\"    [{len(triples)-5+j}] {t[0]!r}  --({t[1]})-->  {t[2]!r}\")\n\n    # Check if q_entity and a_entity appear as graph nodes\n    q_ents = ex['q_entity'] if isinstance(ex['q_entity'], list) else [ex['q_entity']]\n    a_ents = ex['a_entity'] if isinstance(ex['a_entity'], list) else [ex['a_entity']]\n\n    print(f\"\\n  q_entity in graph nodes: \", end=\"\")\n    for qe in q_ents:\n        found = qe in all_entities\n        print(f\"{qe!r} -> {'YES' if found else 'NO'}\", end=\"  \")\n    print()\n\n    print(f\"  a_entity in graph nodes: \", end=\"\")\n    for ae in a_ents:\n        found = ae in all_entities\n        print(f\"{ae!r} -> {'YES' if found else 'NO'}\", end=\"  \")\n    print()\n\n    # Top 5 relations by frequency\n    print(f\"\\n  Top 5 relations:\")\n    for rel, cnt in rel_counts.most_common(5):\n        print(f\"    {cnt:4d}x  {rel}\")\n\n    # Entity name analysis — are they readable or opaque IDs?\n    sample_entities = sorted(all_entities)[:15]\n    print(f\"\\n  Sample entity names (first 15 alphabetically):\")\n    for ent in sample_entities:\n        print(f\"    {ent!r}\")\n\n# ── Cross-example summary ──────────────────────────────────────────────\nprint(f\"\\n{'=' * 70}\")\nprint(\"CROSS-EXAMPLE SUMMARY\")\nprint(f\"{'=' * 70}\")\n\n# Check entity overlap between examples\nall_ex_entities = []\nfor i in range(3):\n    ex = dataset[\"train\"][i]\n    ents = set()\n    for t in ex['graph']:\n        ents.add(t[0])\n        ents.add(t[2])\n    all_ex_entities.append(ents)\n\noverlap_01 = all_ex_entities[0] & all_ex_entities[1]\noverlap_02 = all_ex_entities[0] & all_ex_entities[2]\noverlap_12 = all_ex_entities[1] & all_ex_entities[2]\n\nprint(f\"\\nEntity overlap between examples:\")\nprint(f\"  Ex0 ∩ Ex1: {len(overlap_01)} shared entities\")\nprint(f\"  Ex0 ∩ Ex2: {len(overlap_02)} shared entities\")\nprint(f\"  Ex1 ∩ Ex2: {len(overlap_12)} shared entities\")\nif overlap_01:\n    print(f\"  Sample shared (0∩1): {sorted(overlap_01)[:5]}\")\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tpm668x2XzJ"
   },
   "source": [
    "## Cell 7: Graph Construction\n",
    "\n",
    "Build NetworkX graphs from dataset triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "UBzceOT52XzJ",
    "outputId": "41cf1cce-b004-49d3-c3dd-155b0d0d3c21"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ GraphBuilder initialized (directed=True)\n",
      "Loading unified graph from checkpoint...\n",
      "✓ Checkpoint loaded: /content/drive/MyDrive/arcOS_benchmark/checkpoints/unified_graph.pkl (pickle)\n",
      "\n",
      "============================================================\n",
      "Unified Training Graph Information\n",
      "============================================================\n",
      "Nodes: 543170\n",
      "Edges: 1553935\n",
      "Directed: True\n",
      "Density: 0.000005\n",
      "Weakly connected: True\n",
      "\n",
      "Relation Statistics:\n",
      "Unique relations: 4797\n",
      "Top 10 relations:\n",
      "  - common.topic.notable_types: 73649\n",
      "  - freebase.valuenotation.is_reviewed: 39352\n",
      "  - location.location.containedby: 34265\n",
      "  - common.topic.notable_for: 33116\n",
      "  - people.person.profession: 25576\n",
      "  - people.person.gender: 22162\n",
      "  - common.topic.article: 19550\n",
      "  - people.person.nationality: 19116\n",
      "  - common.topic.webpage: 18736\n",
      "  - common.webpage.topic: 18719\n",
      "\n",
      "Degree Statistics:\n",
      "Average in-degree: 2.86\n",
      "Average out-degree: 2.86\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Graph Size Validation\n",
      "============================================================\n",
      "Nodes: 543170 ✓\n",
      "Edges: 1553935 ✓\n",
      "\n",
      "✓ Graph meets size requirements\n",
      "============================================================\n",
      "\n",
      "Building sample per-example graph...\n",
      "\n",
      "============================================================\n",
      "Sample Per-Example Graph Information\n",
      "============================================================\n",
      "Nodes: 1723\n",
      "Edges: 8286\n",
      "Directed: True\n",
      "Density: 0.002793\n",
      "Weakly connected: True\n",
      "\n",
      "Relation Statistics:\n",
      "Unique relations: 320\n",
      "Top 10 relations:\n",
      "  - freebase.valuenotation.is_reviewed: 898\n",
      "  - broadcast.content.artist: 771\n",
      "  - music.artist.genre: 742\n",
      "  - broadcast.artist.content: 631\n",
      "  - people.person.profession: 614\n",
      "  - common.topic.notable_types: 395\n",
      "  - people.person.gender: 208\n",
      "  - people.person.nationality: 179\n",
      "  - broadcast.content.genre: 136\n",
      "  - common.topic.notable_for: 135\n",
      "\n",
      "Degree Statistics:\n",
      "Average in-degree: 4.81\n",
      "Average out-degree: 4.81\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize graph builder\n",
    "graph_builder = GraphBuilder(directed=config.graph_directed)\n",
    "\n",
    "# Check for cached unified graph\n",
    "unified_graph_path = config.get_checkpoint_path(\"unified_graph.pkl\")\n",
    "\n",
    "if checkpoint_exists(unified_graph_path):\n",
    "    print(\"Loading unified graph from checkpoint...\")\n",
    "    unified_graph = load_checkpoint(unified_graph_path, format=\"pickle\")\n",
    "else:\n",
    "    print(\"Building unified graph from training split...\")\n",
    "    unified_graph = graph_builder.build_unified_graph(dataset[\"train\"])\n",
    "    save_checkpoint(unified_graph, unified_graph_path, format=\"pickle\")\n",
    "\n",
    "# Print graph statistics\n",
    "graph_builder.print_graph_info(unified_graph, name=\"Unified Training Graph\")\n",
    "\n",
    "# Validate graph size\n",
    "graph_valid = graph_builder.validate_graph_size(\n",
    "    unified_graph,\n",
    "    min_nodes=config.unified_graph_min_nodes,\n",
    "    min_edges=config.unified_graph_min_edges,\n",
    ")\n",
    "\n",
    "# Build sample per-example graph for demonstration\n",
    "print(\"\\nBuilding sample per-example graph...\")\n",
    "sample_example = dataset[\"train\"][0]\n",
    "sample_graph = graph_builder.build_from_triples(\n",
    "    sample_example[\"graph\"],\n",
    "    graph_id=sample_example[\"id\"]\n",
    ")\n",
    "graph_builder.print_graph_info(sample_graph, name=\"Sample Per-Example Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pHieT482XzJ"
   },
   "source": [
    "## Cell 8: Phase 1 Validation\n",
    "\n",
    "Automated validation of all Phase 1 success criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEm6SVWK2XzK"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Phase 1 Success Criteria Validation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Collect validation results\n",
    "validation_results = {\n",
    "    \"GPU Available\": torch.cuda.is_available(),\n",
    "    \"All Imports Successful\": True,  # If we got here, imports worked\n",
    "    \"Dataset Splits Valid\": split_valid,\n",
    "    \"Unified Graph Size Valid\": graph_valid,\n",
    "}\n",
    "\n",
    "# Test checkpoint round-trip\n",
    "test_checkpoint_path = config.get_checkpoint_path(\"test_roundtrip.pkl\")\n",
    "test_data = {\"test\": \"round-trip\", \"value\": 42}\n",
    "try:\n",
    "    save_checkpoint(test_data, test_checkpoint_path, format=\"pickle\")\n",
    "    loaded_data = load_checkpoint(test_checkpoint_path, format=\"pickle\")\n",
    "    checkpoint_roundtrip_ok = (loaded_data == test_data)\n",
    "    validation_results[\"Checkpoint Round-Trip\"] = checkpoint_roundtrip_ok\n",
    "except Exception as e:\n",
    "    print(f\"Checkpoint round-trip failed: {e}\")\n",
    "    validation_results[\"Checkpoint Round-Trip\"] = False\n",
    "\n",
    "# Print results\n",
    "print(\"\\nValidation Results:\")\n",
    "all_passed = True\n",
    "for criterion, passed in validation_results.items():\n",
    "    status = \"✓\" if passed else \"✗\"\n",
    "    print(f\"  {status} {criterion}\")\n",
    "    if not passed:\n",
    "        all_passed = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_passed:\n",
    "    print(\"✓ PHASE 1 COMPLETE - All criteria passed!\")\n",
    "    print(\"\\nReady to proceed to Phase 2: Retrieval Pipeline\")\n",
    "else:\n",
    "    print(\"✗ PHASE 1 INCOMPLETE - Some criteria failed\")\n",
    "    print(\"\\nPlease review failed criteria above\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nPhase 1 Summary:\")\n",
    "print(f\"  Dataset: {config.dataset_name}\")\n",
    "print(f\"  Training examples: {len(dataset['train'])}\")\n",
    "print(f\"  Validation examples: {len(dataset['validation'])}\")\n",
    "print(f\"  Test examples: {len(dataset['test'])}\")\n",
    "print(f\"  Unified graph nodes: {unified_graph.number_of_nodes()}\")\n",
    "print(f\"  Unified graph edges: {unified_graph.number_of_edges()}\")\n",
    "print(f\"  Checkpoints saved to: {config.checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8.5: PCST Configuration\n",
    "\n",
    "Override retrieval hyperparameters **without editing  or pushing to GitHub**.\n",
    "These assignments mutate the  object created in Cell 3 — run this cell before Cell 9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PCST CONFIGURATION — override config.py defaults here\n",
    "# Edit values below, then run this cell.\n",
    "# Works whether Cell 9 has already run or not.\n",
    "# ============================================================\n",
    "\n",
    "# Max nodes in the extracted subgraph\n",
    "config.pcst_budget = 70\n",
    "\n",
    "# BFS neighbourhood size: nodes collected around seeds before PCST runs\n",
    "config.pcst_local_budget = 300\n",
    "\n",
    "# Edge traversal cost. Lower = more edges included.\n",
    "# With cosine-sim prizes in [0, 1], 0.015 lets a 4-hop path reach a 0.4-prize node.\n",
    "config.pcst_cost = 0.015\n",
    "\n",
    "# PCST pruning strategy: \"none\", \"gw\" (Goemans-Williamson), or \"strong\"\n",
    "config.pcst_pruning = \"gw\"\n",
    "\n",
    "# Query-aware edge cost scaling [0, 1].\n",
    "# 0 = uniform costs  |  1 = fully query-aware (similar edges are cheaper)\n",
    "config.pcst_edge_weight_alpha = 0.5\n",
    "\n",
    "# Bridge disconnected PCST components via shortest paths\n",
    "config.pcst_bridge_components = True\n",
    "\n",
    "# Max relay hops when bridging disconnected components\n",
    "config.pcst_bridge_max_hops = 6\n",
    "\n",
    "# ── Validate ─────────────────────────────────────────────────\n",
    "config.__post_init__()  # re-run validation with updated values\n",
    "\n",
    "# ── Live-patch retriever if already built ─────────────────────\n",
    "# If Cell 9 already ran, update the live PCSTSolver directly so\n",
    "# you do not need to re-run Cell 9.\n",
    "try:\n",
    "    solver = retriever.pcst_solver\n",
    "    solver.cost              = config.pcst_cost\n",
    "    solver.budget            = config.pcst_budget\n",
    "    solver.local_budget      = config.pcst_local_budget\n",
    "    solver.pruning           = config.pcst_pruning\n",
    "    solver.edge_weight_alpha = config.pcst_edge_weight_alpha\n",
    "    solver.bridge_components = config.pcst_bridge_components\n",
    "    solver.bridge_max_hops   = config.pcst_bridge_max_hops\n",
    "    _src = \"config + live retriever\"\n",
    "except NameError:\n",
    "    _src = \"config only (retriever not built yet — run Cell 9)\"\n",
    "\n",
    "print(f\"PCST configuration applied ({_src}):\")\n",
    "print(f\"  pcst_budget            = {config.pcst_budget}\")\n",
    "print(f\"  pcst_local_budget      = {config.pcst_local_budget}\")\n",
    "print(f\"  pcst_cost              = {config.pcst_cost}\")\n",
    "print(f\"  pcst_pruning           = {config.pcst_pruning\\!r}\")\n",
    "print(f\"  pcst_edge_weight_alpha = {config.pcst_edge_weight_alpha}\")\n",
    "print(f\"  pcst_bridge_components = {config.pcst_bridge_components}\")\n",
    "print(f\"  pcst_bridge_max_hops   = {config.pcst_bridge_max_hops}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FN_Yhru52XzK"
   },
   "source": [
    "## Cell 9: Build Retrieval Pipeline\n",
    "\n",
    "Initialize retrieval components (embeddings, FAISS index, PCST solver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BXng-Wzu1U8c",
    "outputId": "21c3466a-6ee0-41f3-ea25-8e04914dbf6d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 82ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install pcst-fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1d27e88c95a543eaa1fca95bba175bc2",
      "9cdbecb3c4cd498781a8bc2aa4908b79",
      "7a9e86028b464db48aaa4ea2f091c73d",
      "c451c251ecb04fe1b9d958356ebd7208",
      "0ef51609179642868ef0bf206e15f4bc",
      "f04f14dfe1934393aa0e0f5a1997d560",
      "07534a33162147a18729b7ba809c6fa0",
      "32373580d4a749fdbb1e883a633c1410",
      "1d5922861d564afc89aedb8c0e4b3820",
      "36c27afb2b514dcc9161f223bfb1a6d1",
      "89ce6627513340fb91b36ab40b89a4b7"
     ]
    },
    "id": "I48MWhc62XzL",
    "outputId": "88e9eee2-ada7-486d-bd8e-59b12a93f68d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================================================\n",
      "PHASE 2: RETRIEVAL PIPELINE\n",
      "============================================================\n",
      "============================================================\n",
      "BUILDING RETRIEVAL PIPELINE\n",
      "============================================================\n",
      "\n",
      "[1/4] Initializing text embedder...\n",
      "⚠ CUDA not available, falling back to CPU for embeddings\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d27e88c95a543eaa1fca95bba175bc2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✓ Loaded embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "  - Device: cpu\n",
      "  - Embedding dimension: 384\n",
      "\n",
      "[2/4] Loading/computing entity embeddings...\n",
      "Loading cached embeddings from entity_embeddings.pkl\n",
      "✓ Checkpoint loaded: /content/drive/MyDrive/arcOS_benchmark/checkpoints/entity_embeddings.pkl (pickle)\n",
      "✓ Loaded 543170 entity embeddings\n",
      "\n",
      "[3/4] Loading/computing relation embeddings...\n",
      "Loading cached relation embeddings from relation_embeddings.pkl\n",
      "✓ Checkpoint loaded: /content/drive/MyDrive/arcOS_benchmark/checkpoints/relation_embeddings.pkl (pickle)\n",
      "✓ Loaded 4797 relation embeddings\n",
      "\n",
      "[4/4] Loading/building FAISS index...\n",
      "Loading cached FAISS index from faiss_index.bin\n",
      "✓ Loaded FAISS index from /content/drive/MyDrive/arcOS_benchmark/checkpoints/faiss_index.bin\n",
      "  - 543170 entities indexed\n",
      "\n",
      "Initializing PCST solver...\n",
      "✓ PCST solver ready (cost: 1.0, budget: 70, local: 300, pruning: gw, base_prize_ratio: 1.0)\n",
      "\n",
      "============================================================\n",
      "✓ RETRIEVAL PIPELINE READY\n",
      "============================================================\n",
      "\n",
      "✓ Retrieval pipeline initialized\n",
      "  - Entity embeddings: 543170 entities\n",
      "  - Top-K: 15\n",
      "  - PCST budget: 70 nodes\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PHASE 2: RETRIEVAL PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from src.retrieval import Retriever\n",
    "\n",
    "# Build retriever (uses checkpoints if available)\n",
    "retriever = Retriever.build_from_checkpoint_or_new(\n",
    "    config=config,\n",
    "    unified_graph=unified_graph  # From Phase 1 Cell 7\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Retrieval pipeline initialized\")\n",
    "print(f\"  - Entity embeddings: {len(retriever.entity_index)} entities\")\n",
    "print(f\"  - Top-K: {config.top_k_entities}\")\n",
    "print(f\"  - PCST budget: {config.pcst_budget} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VwowPg62XzL"
   },
   "source": [
    "## Cell 10: Retrieval Validation\n",
    "\n",
    "Test retrieval pipeline on 10 validation examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfRB6T_p2XzL",
    "outputId": "2d7d6e7c-32a4-419a-faf7-0d0b8a7cf84e"
   },
   "outputs": [],
   "source": "print(\"\\n\" + \"=\" * 60)\nprint(\"RETRIEVAL VALIDATION (up to 50 examples)\")\nprint(\"=\" * 60)\n\n# Use up to 50 validation examples for statistically meaningful results\nn_val = min(50, len(dataset[\"validation\"]))\nval_examples = list(dataset[\"validation\"].select(range(n_val)))\n\nhit_count = 0\ntotal_time_ms = 0\nsubgraph_sizes = []\n\nfor i, example in enumerate(val_examples):\n    question = example[\"question\"]\n    answer_entities = example.get(\"a_entity\", [])\n    if isinstance(answer_entities, str):\n        answer_entities = [answer_entities]\n\n    # Extract topic entities from dataset\n    q_entities = example.get(\"q_entity\", [])\n    if isinstance(q_entities, str):\n        q_entities = [q_entities]\n\n    # Print header BEFORE retrieve() so PCST verbose output appears\n    # under the correct example (not visually under the previous one)\n    print(f\"\\n[{i+1}/{n_val}] Q: {question[:60]}...\")\n    print(f\"  Topic entities (q_entity): {q_entities}\")\n    print(f\"  Answer entities: {answer_entities}\")\n\n    # Retrieve subgraph (q_entity used as primary seed when available)\n    result = retriever.retrieve(question, q_entity=q_entities, answer_entities=answer_entities)\n\n    # has_answer is now set on the result by retrieve()\n    hit = result.has_answer\n\n    if hit:\n        hit_count += 1\n\n    total_time_ms += result.retrieval_time_ms\n    subgraph_sizes.append(result.num_nodes)\n\n    # Print result summary (after PCST verbose output)\n    print(f\"  Seeds used: {result.seed_entities[:5]}{'...' if len(result.seed_entities) > 5 else ''}\")\n    print(f\"  Subgraph: {result.num_nodes} nodes, {result.num_edges} edges\")\n    print(f\"  Hit: {'✓' if hit else '✗'}\")\n    print(f\"  Time: {result.retrieval_time_ms:.1f}ms\")\n\n# Summary metrics\nhit_rate = hit_count / len(val_examples) * 100\navg_time = total_time_ms / len(val_examples)\navg_size = sum(subgraph_sizes) / len(subgraph_sizes)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"VALIDATION SUMMARY\")\nprint(\"=\" * 60)\nprint(f\"Hit rate: {hit_rate:.1f}% ({hit_count}/{len(val_examples)})\")\nprint(f\"Avg retrieval time: {avg_time:.1f}ms\")\nprint(f\"Avg subgraph size: {avg_size:.1f} nodes\")\nprint(f\"Max subgraph size: {max(subgraph_sizes)} nodes\")"
  },
  {
   "cell_type": "markdown",
   "source": "## Cell 10a: PCST Deep Dive — Diagnostics\n\nTraces a **single failing example** (smallest subgraph output from Cell 10) through\nevery step of the retrieval pipeline to pinpoint why PCST collapses to 1 node.\n\n**Steps traced:**\n\n| Step | What it checks |\n|------|---------------|\n| **A** | Query embedding norm |\n| **B** | k-NN seed scores and graph membership |\n| **C** | Prize construction — how many seeds get prizes and whether any prize > edge cost |\n| **D** | BFS localisation — local graph size, number of WCCs, root component size, answer entity reachability |\n| **E** | Local prize computation — entity-embedding coverage, how many nodes clear the `local_prize_threshold`, how many exceed `cost` |\n| **F** | Raw `pcst_fast` call — prize/cost ratio, output format (labels vs indices), final node count |\n\n**Visualisations:**\n- Prize distribution histogram vs edge-cost line (Plot 1)\n- Pipeline funnel: node count at each stage (Plot 2)\n- Subgraph-size distribution across all 50 val examples (Plot 3)\n- Root-component graph coloured by node type / prize magnitude (Plot 4)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# CELL 10a: PCST DEEP DIVE — Step-by-step diagnostics for one failing example\n#\n# Traces: query → k-NN → prizes → BFS localise → root component →\n#         local prizes → raw pcst_fast call → output\n# Highlights exactly where and why PCST collapses to 1 node.\n# ============================================================================\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport networkx as nx\nfrom collections import Counter\n\ntry:\n    import pcst_fast as _pcst_fast_mod\nexcept ImportError:\n    _pcst_fast_mod = None\n    print(\"⚠ pcst_fast not importable — Step F will be skipped\")\n\n# ── Pick probe example: prefer one where PCST returned ≤ 2 nodes ──────────\n_failing   = [i for i, s in enumerate(subgraph_sizes) if s <= 2]\n_probe_idx = _failing[0] if _failing else 0\n_ex        = val_examples[_probe_idx]\n_q         = _ex[\"question\"]\n_q_ents    = _ex.get(\"q_entity\", [])\nif isinstance(_q_ents, str): _q_ents = [_q_ents]\n_a_ents    = _ex.get(\"a_entity\", [])\nif isinstance(_a_ents, str): _a_ents = [_a_ents]\n_solver    = retriever.pcst_solver\n\nprint(\"=\" * 70)\nprint(f\"PROBE  [{_probe_idx}]: {_ex['id']}\")\nprint(f\"  Q        : {_q}\")\nprint(f\"  q_entity : {_q_ents}\")\nprint(f\"  a_entity : {_a_ents}\")\nprint(\"=\" * 70)\n\n# ── A: Query embedding ─────────────────────────────────────────────────────\n_qemb = retriever.embedder.embed_texts([_q], show_progress=False)[0]\nprint(f\"\\n[A] Query embedding  shape={_qemb.shape}  norm={np.linalg.norm(_qemb):.4f}\")\n\n# ── B: k-NN search ────────────────────────────────────────────────────────\n_knn = retriever.entity_index.search(_qemb, k=config.top_k_entities)\nprint(f\"\\n[B] k-NN top-{config.top_k_entities}  (score | in_graph | name):\")\nfor _ent, _sc in _knn:\n    _tags = (\"  ← q_entity\" if _ent in _q_ents else \"\") + \\\n            (\"  ← a_entity\" if _ent in _a_ents else \"\")\n    print(f\"  {_sc:.4f}  {'✓' if _ent in retriever.unified_graph else '✗'}  \"\n          f\"{_ent[:55]}{_tags}\")\n\n# ── C: Seed list & prize construction (mirrors retriever.retrieve) ─────────\n_seed_ents, _sim_scores, _q_ent_names = [], {}, set()\nfor _qe in _q_ents:\n    if _qe in retriever.unified_graph:\n        _seed_ents.append(_qe); _sim_scores[_qe] = 1.0; _q_ent_names.add(_qe)\nfor _ent, _sc in _knn:\n    if _ent not in _sim_scores:\n        _seed_ents.append(_ent); _sim_scores[_ent] = _sc\n\n_SIM_THRESH = 0.4\n_prizes = {_qe: 1.0 for _qe in _q_ent_names}\nfor _ent, _sc in _knn:\n    if _ent not in _prizes and _sc >= _SIM_THRESH:\n        _prizes[_ent] = float(_sc)\n\nprint(f\"\\n[C] Seeds & global prizes:\")\nprint(f\"  Seeds total         : {len(_seed_ents)}\")\nprint(f\"  Seeds in graph      : {sum(1 for s in _seed_ents if s in retriever.unified_graph)}\")\nprint(f\"  Prized nodes (global): {len(_prizes)}\")\nif _prizes:\n    _pv = list(_prizes.values())\n    print(f\"  Prize range         : {min(_pv):.4f} – {max(_pv):.4f}\")\nprint(f\"  PCST edge cost      : {_solver.cost}\")\n_c_above = sum(1 for p in _prizes.values() if p > _solver.cost) if _prizes else 0\nprint(f\"  Prizes > cost       : {_c_above}/{len(_prizes)}\")\nif _prizes and _c_above == 0:\n    print(f\"  ⚠ ALL GLOBAL PRIZES ≤ COST — every edge is net-negative before local prizes\")\nelif not _prizes:\n    print(f\"  ⚠ NO PRIZES — no k-NN seed scored ≥ {_SIM_THRESH} similarity threshold\")\n\n# ── D: BFS localisation ────────────────────────────────────────────────────\n_root_arg  = list(_q_ent_names) or None\n_local_g   = _solver._localize(retriever.unified_graph, _seed_ents, root_entities=_root_arg)\n_root_node = _solver._pick_root(_local_g, _seed_ents, _root_arg, _prizes)\n_root_comp, _n_comps = _solver._root_component(_local_g, _root_node)\n_prized_in_root = {n: _prizes[n] for n in _prizes if n in _root_comp}\n\nprint(f\"\\n[D] BFS localisation (budget={_solver.local_budget}):\")\nprint(f\"  Local graph         : {len(_local_g)} nodes, {_local_g.number_of_edges()} edges\")\nprint(f\"  WCC in local graph  : {_n_comps}\")\nprint(f\"  Selected root       : '{_root_node[:60]}'\")\nprint(f\"  Root component      : {len(_root_comp)} nodes, {_root_comp.number_of_edges()} edges\")\nprint(f\"  k-NN prizes in root : {len(_prized_in_root)} / {len(_prizes)}\")\nif len(_prized_in_root) < len(_prizes):\n    _missing = [n for n in _prizes if n not in _root_comp]\n    print(f\"  Prized nodes NOT in root component: {_missing[:5]}\"\n          f\"{'...' if len(_missing) > 5 else ''}\")\n\nprint(f\"\\n  Answer entity trace:\")\nfor _ae in _a_ents[:4]:\n    _in_g = _ae in retriever.unified_graph\n    _in_l = _ae in _local_g\n    _in_r = _ae in _root_comp\n    _dist = \"?\"\n    if _in_r and _ae != _root_node:\n        try:\n            _dist = nx.shortest_path_length(_root_comp.to_undirected(), _root_node, _ae)\n        except (nx.NetworkXNoPath, nx.NodeNotFound):\n            _dist = \"disconnected\"\n    elif _ae == _root_node:\n        _dist = 0\n    print(f\"    '{_ae[:45]}': in_graph={_in_g}, in_local={_in_l}, \"\n          f\"in_root={_in_r}, hops_from_root={_dist}\")\n\n# ── E: Local prize computation ─────────────────────────────────────────────\n_local_prizes = _solver._compute_local_prizes(\n    _root_comp, _prizes, _qemb, retriever.entity_embeddings)\n_all_prized = {n: p for n, p in _local_prizes.items() if p > 0}\n_above_cost = {n: p for n, p in _local_prizes.items() if p > _solver.cost}\n_n_with_emb = sum(1 for n in _root_comp if n in retriever.entity_embeddings)\n\nprint(f\"\\n[E] Local prizes (merged: global k-NN + local cosine sim + existence):\")\nprint(f\"  Nodes in root comp      : {len(_root_comp)}\")\nprint(f\"  With entity embedding   : {_n_with_emb} ({_n_with_emb/max(len(_root_comp),1)*100:.0f}%)\")\nprint(f\"  local_prize_threshold   : {_solver.local_prize_threshold}\")\nprint(f\"  existence_prize         : {_solver.existence_prize}\")\nprint(f\"  Nodes with prize > 0    : {len(_all_prized)}\")\nprint(f\"  Nodes with prize > cost : {len(_above_cost)}  (cost={_solver.cost})\")\nif _all_prized:\n    _lpv = sorted(_all_prized.values(), reverse=True)\n    print(f\"  Prize top-5             : {[f'{p:.4f}' for p in _lpv[:5]]}\")\n    print(f\"  Prize mean / max        : {sum(_lpv)/len(_lpv):.4f} / {_lpv[0]:.4f}\")\n\nif not _all_prized:\n    print(f\"\\n  ⚠ CRITICAL: Zero prizes in root component — PCST will return only root!\")\nelif not _above_cost:\n    print(f\"\\n  ⚠ CRITICAL: Max prize ({max(_all_prized.values()):.4f}) ≤ \"\n          f\"cost ({_solver.cost}) — PCST returns only root!\")\nelse:\n    print(f\"\\n  ✓ {len(_above_cost)} node(s) have prize > cost — PCST should expand from root\")\n\n# ── F: Raw pcst_fast call ──────────────────────────────────────────────────\nprint(f\"\\n[F] Raw pcst_fast call:\")\n_sel = np.array([0])  # fallback\nif _pcst_fast_mod is not None and _root_comp.number_of_edges() > 0:\n    _G_und   = _root_comp.to_undirected()\n    _nodes   = list(_G_und.nodes())\n    _n2i     = {n: i for i, n in enumerate(_nodes)}\n    _edges_l = [(int(_n2i[u]), int(_n2i[v])) for u, v in _G_und.edges()]\n    _ea      = np.array(_edges_l, dtype=np.int32)\n    _pa      = np.zeros(len(_nodes), dtype=np.float64)\n    for _n, _p in _local_prizes.items():\n        if _n in _n2i:\n            _pa[_n2i[_n]] = max(_p, 0.0)\n    _ca = np.full(len(_edges_l), _solver.cost, dtype=np.float64)\n    _ca = np.maximum(_ca, 1e-9)\n\n    _re = next((_qe for _qe in _q_ents if _qe in _n2i), None)\n    if _re is None:\n        _re = max((_s for _s in _seed_ents if _s in _n2i),\n                  key=lambda s: _local_prizes.get(s, 0.0), default=_nodes[0])\n    _ri = int(_n2i[_re])\n\n    print(f\"  nodes={len(_nodes)}, edges={len(_edges_l)}, \"\n          f\"root='{_re[:40]}' (idx={_ri})\")\n    print(f\"  edge cost={_solver.cost}, pruning='{_solver.pruning}'\")\n    print(f\"  scored nodes       : {int(np.count_nonzero(_pa))}\")\n    print(f\"  prize array        : max={_pa.max():.6f}  \"\n          f\"mean(>0)={_pa[_pa>0].mean():.6f if _pa.any() else 'N/A'}\")\n    print(f\"  prize / cost ratio : {_pa.max()/_solver.cost:.4f}x  \"\n          f\"(need >1.0 for PCST to expand)\")\n\n    _rn, _ = _pcst_fast_mod.pcst_fast(_ea, _pa, _ca, _ri, 1, _solver.pruning, 0)\n    _rn = np.asarray(_rn, dtype=np.int64)\n\n    print(f\"\\n  Raw output array length : {len(_rn)}\")\n    if len(_rn) == len(_nodes):\n        print(f\"  ➜ LABELS format (len == num_nodes={len(_nodes)})\")\n        _rl  = int(_rn[_ri])\n        _sel = np.where(_rn == _rl)[0]\n        print(f\"  Root label={_rl}, nodes in root cluster: {len(_sel)}\")\n    else:\n        print(f\"  ➜ INDICES format\")\n        _sel = np.unique(_rn)\n        _sel = _sel[(_sel >= 0) & (_sel < len(_nodes))]\n\n    print(f\"\\n  *** PCST selected {len(_sel)} node(s) ***\")\n    for _i in _sel[:10]:\n        print(f\"    [{_i}] '{_nodes[_i][:55]}'  prize={_pa[_i]:.4f}\")\n    if len(_sel) > 10:\n        print(f\"    ... and {len(_sel)-10} more\")\nelse:\n    print(\"  Skipped — no edges in root component or pcst_fast not available\")\n    _nodes = list(_root_comp.nodes())\n    _n2i   = {n: i for i, n in enumerate(_nodes)}\n    _pa    = np.zeros(len(_nodes))\n    for _n, _p in _local_prizes.items():\n        if _n in _n2i: _pa[_n2i[_n]] = max(_p, 0.0)\n\n# ── VISUALISATIONS ─────────────────────────────────────────────────────────\nfig, axes = plt.subplots(1, 3, figsize=(20, 5))\nfig.suptitle(f\"PCST Diagnostics | {_ex['id']}: \\\"{_q[:70]}\\\"\", fontsize=10)\n\n# Plot 1 – Prize distribution vs edge cost\nax = axes[0]\n_pviz = [p for p in _local_prizes.values() if p > 0]\nif _pviz:\n    ax.hist(_pviz, bins=min(40, len(_pviz)), color='#42A5F5', edgecolor='white', alpha=0.85)\n    ax.axvline(_solver.cost, color='#EF5350', lw=2.5, linestyle='--',\n               label=f'Edge cost = {_solver.cost}')\n    ax.set_xlabel(\"Prize value\"); ax.set_ylabel(\"# nodes\")\n    ax.set_title(\"Prize Distribution vs Edge Cost\"); ax.legend()\n    _nb = sum(1 for p in _pviz if p <= _solver.cost)\n    _na = sum(1 for p in _pviz if p > _solver.cost)\n    ax.text(0.97, 0.97, f\"≤ cost: {_nb}\\n> cost: {_na}\",\n            transform=ax.transAxes, va='top', ha='right', fontsize=9,\n            bbox=dict(boxstyle='round', fc='lightyellow', alpha=0.8))\nelse:\n    ax.text(0.5, 0.5, \"No prizes in\\nroot component\", ha='center', va='center',\n            fontsize=14, color='#EF5350', transform=ax.transAxes)\n    ax.set_title(\"Prize Distribution vs Edge Cost\")\n\n# Plot 2 – Pipeline funnel (node counts at each stage)\nax = axes[1]\n_funnel = [\n    (\"k-NN seeds\",      len(_seed_ents)),\n    (\"BFS local\",       len(_local_g)),\n    (\"Root comp\",       len(_root_comp)),\n    (\"Prized (>0)\",     len(_all_prized)),\n    (\"Above cost\",      len(_above_cost)),\n    (\"PCST output\",     len(_sel)),\n]\n_fl, _fv = [f[0] for f in _funnel][::-1], [f[1] for f in _funnel][::-1]\n_fc = ['#0D47A1','#1B5E20','#E65100','#4A148C','#B71C1C','#004D40'][::-1]\n_fb = ax.barh(_fl, _fv, color=_fc, alpha=0.85)\nfor _bar, _val in zip(_fb, _fv):\n    ax.text(_bar.get_width() + max(_fv)*0.01 + 0.5,\n            _bar.get_y() + _bar.get_height()/2,\n            str(_val), va='center', fontsize=10, fontweight='bold')\nax.set_xlabel(\"# nodes\"); ax.set_title(\"Pipeline Funnel (single example)\")\nax.grid(axis='x', alpha=0.3); ax.set_xlim(0, max(max(_fv), 1) * 1.18)\n\n# Plot 3 – Subgraph size distribution across all 50 val examples\nax = axes[2]\nax.hist(subgraph_sizes, bins=range(0, max(subgraph_sizes) + 2),\n        color='#42A5F5', edgecolor='white', alpha=0.85)\nax.axvline(1.5, color='#EF5350', lw=2, linestyle='--', label='Size ≤ 1 (degenerate)')\nax.set_xlabel(\"Subgraph size (nodes)\"); ax.set_ylabel(\"# examples\")\nax.set_title(f\"Subgraph Sizes across {len(subgraph_sizes)} val examples\"); ax.legend()\n_ndeg = sum(1 for s in subgraph_sizes if s <= 1)\nax.text(0.97, 0.97, f\"Degenerate (≤1): {_ndeg}/{len(subgraph_sizes)}\\n\"\n        f\"Hit rate: {hit_rate:.1f}%\\nMean size: {avg_size:.1f}\",\n        transform=ax.transAxes, va='top', ha='right', fontsize=9,\n        bbox=dict(boxstyle='round', fc='lightyellow', alpha=0.8))\n\nplt.tight_layout(); plt.show()\n\n# ── Graph: root component coloured by prize ────────────────────────────────\n_top_n = min(60, len(_root_comp))\n_top_nodes = [n for n, _ in sorted(_local_prizes.items(),\n              key=lambda x: x[1], reverse=True)][:_top_n]\n_G_viz = _root_comp.subgraph(_top_nodes).copy()\n\nif len(_G_viz) > 1:\n    _pos = nx.spring_layout(_G_viz, k=2.0/max(len(_G_viz)**0.5, 1),\n                             iterations=60, seed=42)\n    _ncolors, _nsizes = [], []\n    for _nd in _G_viz.nodes():\n        _pr = _local_prizes.get(_nd, 0.0)\n        if _nd in _a_ents:         _ncolors.append('#FF1744')  # answer\n        elif _nd in _q_ent_names:  _ncolors.append('#00C853')  # root/q_entity\n        elif _pr > _solver.cost:   _ncolors.append('#1565C0')  # high prize\n        elif _pr > 0:              _ncolors.append('#90CAF9')  # low prize\n        else:                      _ncolors.append('#BDBDBD')  # relay only\n        _nsizes.append(max(150, min(_pr * 4000, 1500)))\n\n    fig2, ax2 = plt.subplots(figsize=(14, 9))\n    nx.draw_networkx_edges(_G_viz, _pos, ax=ax2, alpha=0.12, arrows=True, arrowsize=7)\n    nx.draw_networkx_nodes(_G_viz, _pos, ax=ax2, node_color=_ncolors,\n                           node_size=_nsizes, alpha=0.9)\n    _top15     = [n for n, _ in sorted(_local_prizes.items(),\n                  key=lambda x: x[1], reverse=True)[:15] if n in _G_viz]\n    nx.draw_networkx_labels(_G_viz, _pos, {n: n[:18] for n in _top15},\n                            ax=ax2, font_size=7)\n    ax2.legend(handles=[\n        mpatches.Patch(color='#00C853', label='q_entity (root)'),\n        mpatches.Patch(color='#FF1744', label='answer entity'),\n        mpatches.Patch(color='#1565C0', label=f'prize > cost={_solver.cost}'),\n        mpatches.Patch(color='#90CAF9', label='prize ∈ (0, cost]'),\n        mpatches.Patch(color='#BDBDBD', label='prize = 0 (relay only)'),\n    ], loc='upper right', fontsize=8, title=\"Node type\")\n    ax2.set_title(\n        f\"Root component — top-{_top_n} nodes by prize\\n\"\n        f\"Root: '{_root_node[:60]}'\\n\"\n        f\"Q: \\\"{_q[:90]}\\\"\", fontsize=10)\n    ax2.axis('off'); plt.tight_layout(); plt.show()\nelse:\n    print(f\"Root component has only {len(_G_viz)} visible node(s) — nothing to visualise.\")\n\n# ── Diagnostic summary ─────────────────────────────────────────────────────\nprint(\"\\n\" + \"=\" * 70)\nprint(\"DIAGNOSTIC SUMMARY\")\nprint(\"=\" * 70)\n_diag = [\n    (\"example\",              _ex['id']),\n    (\"q_entity in graph\",    str([q in retriever.unified_graph for q in _q_ents])),\n    (\"global prizes\",        f\"{len(_prizes)} nodes\"),\n    (\"BFS local size\",       f\"{len(_local_g)} nodes ({_n_comps} WCC)\"),\n    (\"root comp size\",       f\"{len(_root_comp)} nodes\"),\n    (\"prized in root\",       f\"{len(_all_prized)} nodes\"),\n    (\"above cost\",           f\"{len(_above_cost)} nodes (cost={_solver.cost})\"),\n    (\"entity emb coverage\",  f\"{_n_with_emb}/{len(_root_comp)} ({_n_with_emb/max(len(_root_comp),1)*100:.0f}%)\"),\n    (\"PCST output\",          f\"{len(_sel)} node(s)\"),\n    (\"solver.pruning\",       repr(_solver.pruning)),\n    (\"local_prize_threshold\",str(_solver.local_prize_threshold)),\n    (\"existence_prize\",      str(_solver.existence_prize)),\n]\nfor _k, _v in _diag:\n    print(f\"  {_k:<26}: {_v}\")\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju6e-sE22XzM"
   },
   "source": [
    "## Cell 11: Phase 2 Success Criteria\n",
    "\n",
    "Validate Phase 2 completion criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEDJ25h_2XzM"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PHASE 2 SUCCESS CRITERIA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Criterion 1: Retrieval speed < 1 second\n",
    "speed_pass = avg_time < 1000  # ms\n",
    "print(f\"[{'✓' if speed_pass else '✗'}] Retrieval completes in <1 second: {avg_time:.1f}ms\")\n",
    "\n",
    "# Criterion 2: Hit rate > 60%\n",
    "hit_pass = hit_rate >= 60.0\n",
    "print(f\"[{'✓' if hit_pass else '✗'}] Subgraph contains answer entity >60%: {hit_rate:.1f}%\")\n",
    "\n",
    "# Criterion 3: All subgraphs connected\n",
    "all_connected = all(\n",
    "    nx.is_weakly_connected(\n",
    "        retriever.retrieve(\n",
    "            example[\"question\"],\n",
    "            q_entity=example.get(\"q_entity\")\n",
    "        ).subgraph\n",
    "    )\n",
    "    for example in val_examples[:5]  # Check first 5\n",
    ")\n",
    "print(f\"[{'✓' if all_connected else '✗'}] All subgraphs are connected\")\n",
    "\n",
    "# Criterion 4: Subgraph size respects budget\n",
    "size_pass = max(subgraph_sizes) <= config.pcst_budget\n",
    "print(f\"[{'✓' if size_pass else '✗'}] Subgraph size ≤ budget ({max(subgraph_sizes)} ≤ {config.pcst_budget})\")\n",
    "\n",
    "# Overall pass\n",
    "all_pass = speed_pass and hit_pass and all_connected and size_pass\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if all_pass:\n",
    "    print(\"✓ PHASE 2 COMPLETE - All criteria met!\")\n",
    "    print(\"\\nReady to proceed to Phase 3: GNN Encoder\")\n",
    "else:\n",
    "    print(\"⚠ PHASE 2 INCOMPLETE - Review failed criteria above\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdPaAEYiab3A"
   },
   "source": [
    "# Phase 3: GNN Encoder\n",
    "## Cell 12: Build/Load GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "8YgdaqamjdWl"
   },
   "outputs": [],
   "source": [
    "!uv pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbTg--JZkzUx"
   },
   "outputs": [],
   "source": [
    "# Install torch_geometric and its dependencies\n",
    "print(\"Installing torch_geometric...\")\n",
    "!uv pip install torch_geometric torch_scatter torch_sparse -f https://data.pyg.org/whl/torch-2.8.0+cu128.html\n",
    "print(\"✓ torch_geometric installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiad8bLiab3B"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PHASE 3: GNN Encoder\n",
    "# ============================================================\n",
    "\n",
    "print(\"Building GNN Model...\")\n",
    "print(\"This will either:\")\n",
    "print(\"  1. Load pre-trained model from checkpoint, OR\")\n",
    "print(\"  2. Prepare data and train from scratch (~30 min)\")\n",
    "print()\n",
    "\n",
    "from src.gnn import GNNModel\n",
    "\n",
    "# Build GNN model (handles checkpoint loading or training automatically)\n",
    "gnn_model = GNNModel.build_from_checkpoint_or_train(\n",
    "    config=config,\n",
    "    retriever=retriever,\n",
    "    train_data=dataset[\"train\"],\n",
    "    val_data=dataset[\"validation\"],\n",
    "    encoder_type=\"gatv2\",  # or \"graphsage\"\n",
    "    pooling_type=\"attention\",  # or \"mean\", \"max\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GNN Model Ready\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BbYDV0Zab3B"
   },
   "source": [
    "## Cell 13: Test GNN Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J90pfuVTab3B"
   },
   "outputs": [],
   "source": [
    "# Test GNN encoding on a single example\n",
    "print(\"Testing GNN inference on example query...\\n\")\n",
    "\n",
    "test_question = \"Who is Justin Bieber's brother?\"\n",
    "print(f\"Question: {test_question}\")\n",
    "\n",
    "# Retrieve subgraph\n",
    "retrieved = retriever.retrieve(test_question)\n",
    "print(f\"Retrieved subgraph: {retrieved.num_nodes} nodes, {retrieved.num_edges} edges\")\n",
    "\n",
    "# Encode with GNN\n",
    "gnn_output = gnn_model.encode(retrieved, test_question)\n",
    "\n",
    "print(f\"\\nGNN Output:\")\n",
    "print(f\"  Node embeddings shape: {gnn_output.node_embeddings.shape}\")\n",
    "print(f\"  Graph embedding shape: {gnn_output.graph_embedding.shape}\")\n",
    "print(f\"  Attention scores: {len(gnn_output.attention_scores)} nodes\")\n",
    "\n",
    "# Get top attention nodes\n",
    "top_nodes = gnn_model.get_top_attention_nodes(gnn_output, top_k=10)\n",
    "print(f\"\\nTop 10 nodes by attention score:\")\n",
    "for i, (node, score) in enumerate(top_nodes, 1):\n",
    "    print(f\"  {i}. {node}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYEaOgU3ab3B"
   },
   "source": [
    "## Cell 14: Validate GNN Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lXQ_Uzgab3B"
   },
   "outputs": [],
   "source": [
    "# Load training history and display metrics\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_path = config.get_checkpoint_path(\"gnn_training_history.json\")\n",
    "with open(history_path, \"r\") as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PHASE 3 VALIDATION: GNN Metrics\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Best metrics\n",
    "best_val_f1 = max(history[\"val_f1\"])\n",
    "best_val_loss = min(history[\"val_loss\"])\n",
    "final_val_f1 = history[\"val_f1\"][-1]\n",
    "\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"  Epochs trained: {len(history['train_loss'])}\")\n",
    "print(f\"  Best validation F1: {best_val_f1:.3f}\")\n",
    "print(f\"  Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"  Final validation F1: {final_val_f1:.3f}\")\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "axes[0].plot(history[\"val_loss\"], label=\"Val Loss\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Training and Validation Loss\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# F1 curve\n",
    "axes[1].plot(history[\"train_f1\"], label=\"Train F1\")\n",
    "axes[1].plot(history[\"val_f1\"], label=\"Val F1\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"F1 Score\")\n",
    "axes[1].set_title(\"Answer Node Prediction F1\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Success criteria check\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Success Criteria:\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "criteria = [\n",
    "    (\"Validation F1 > 0.5\", best_val_f1 > 0.5, best_val_f1),\n",
    "    (\"Training completed < 30 min\", True, \"N/A\"),  # User observation\n",
    "    (\"No OOM errors\", True, \"N/A\"),  # User observation\n",
    "]\n",
    "\n",
    "for criterion, passed, value in criteria:\n",
    "    status = \"✓ PASS\" if passed else \"✗ FAIL\"\n",
    "    print(f\"{status} - {criterion}: {value}\")\n",
    "\n",
    "if all(c[1] for c in criteria):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUCCESS: Phase 3 Complete\")\n",
    "    print(f\"{'='*60}\")\n",
    "else:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"FAILED: Some criteria not met\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V278nVPzab3B"
   },
   "source": [
    "## Cell 15: Visualize Attention on Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0RRpTpHab3B"
   },
   "outputs": [],
   "source": [
    "# Visualize GNN attention on a subgraph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def visualize_gnn_attention(\n",
    "    subgraph: nx.DiGraph,\n",
    "    attention_scores: dict,\n",
    "    answer_entities: list,\n",
    "    question: str,\n",
    "    top_k: int = 20,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize GNN attention on a subgraph.\n",
    "\n",
    "    Args:\n",
    "        subgraph: NetworkX DiGraph\n",
    "        attention_scores: Dict[node_name, float]\n",
    "        answer_entities: List of ground truth answer entities\n",
    "        question: Question text\n",
    "        top_k: Show only top-K nodes by attention\n",
    "    \"\"\"\n",
    "    # Get top-K nodes by attention\n",
    "    sorted_nodes = sorted(\n",
    "        attention_scores.items(), key=lambda x: x[1], reverse=True\n",
    "    )[:top_k]\n",
    "    top_nodes = [node for node, _ in sorted_nodes]\n",
    "\n",
    "    # Create subgraph with only top nodes\n",
    "    G_viz = subgraph.subgraph(top_nodes).copy()\n",
    "\n",
    "    # Node colors (red = answer, blue = high attention, gray = low attention)\n",
    "    node_colors = []\n",
    "    for node in G_viz.nodes():\n",
    "        if node in answer_entities:\n",
    "            node_colors.append(\"red\")\n",
    "        else:\n",
    "            # Scale by attention (darker = higher attention)\n",
    "            attn = attention_scores.get(node, 0.0)\n",
    "            intensity = min(attn * 10, 1.0)  # Scale for visibility\n",
    "            node_colors.append((0.2, 0.4, 0.8, 0.3 + 0.7 * intensity))\n",
    "\n",
    "    # Node sizes proportional to attention\n",
    "    node_sizes = [\n",
    "        300 + 2000 * attention_scores.get(node, 0.0) for node in G_viz.nodes()\n",
    "    ]\n",
    "\n",
    "    # Layout\n",
    "    pos = nx.spring_layout(G_viz, k=0.5, iterations=50, seed=42)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    plt.title(f\"GNN Attention Visualization\\nQ: {question}\", fontsize=12)\n",
    "\n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(\n",
    "        G_viz, pos, alpha=0.3, arrows=True, arrowsize=10, width=1.0\n",
    "    )\n",
    "\n",
    "    # Draw nodes\n",
    "    nx.draw_networkx_nodes(\n",
    "        G_viz, pos, node_color=node_colors, node_size=node_sizes, alpha=0.9\n",
    "    )\n",
    "\n",
    "    # Draw labels (only for top 10)\n",
    "    labels = {node: node[:20] for node in list(G_viz.nodes())[:10]}\n",
    "    nx.draw_networkx_labels(G_viz, pos, labels, font_size=8)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print attention scores\n",
    "    print(\"Top 10 attention scores:\")\n",
    "    for i, (node, score) in enumerate(sorted_nodes[:10], 1):\n",
    "        is_answer = \"✓ ANSWER\" if node in answer_entities else \"\"\n",
    "        print(f\"  {i}. {node[:30]}: {score:.4f} {is_answer}\")\n",
    "\n",
    "\n",
    "# Test visualization\n",
    "test_question = \"Who is Barack Obama's spouse?\"\n",
    "test_answer = [\"Michelle Obama\", \"m.025s5v9\"]  # Freebase ID\n",
    "\n",
    "retrieved = retriever.retrieve(test_question)\n",
    "gnn_output = gnn_model.encode(retrieved, test_question)\n",
    "\n",
    "visualize_gnn_attention(\n",
    "    subgraph=retrieved.subgraph,\n",
    "    attention_scores=gnn_output.attention_scores,\n",
    "    answer_entities=test_answer,\n",
    "    question=test_question,\n",
    "    top_k=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uV1qeDzzab3C"
   },
   "source": [
    "## Cell 16: Memory Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URJaPvgLab3C"
   },
   "outputs": [],
   "source": [
    "# Check GPU memory usage\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Memory Summary:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "    print(f\"  Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "    print(f\"  Max allocated: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "    # Verify no memory leak\n",
    "    assert torch.cuda.memory_allocated() / 1e9 < 14.0, \"Memory leak detected!\"\n",
    "    print(\"\\n✓ Memory usage within acceptable range\")\n",
    "else:\n",
    "    print(\"GPU not available\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1d27e88c95a543eaa1fca95bba175bc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9cdbecb3c4cd498781a8bc2aa4908b79",
       "IPY_MODEL_7a9e86028b464db48aaa4ea2f091c73d",
       "IPY_MODEL_c451c251ecb04fe1b9d958356ebd7208"
      ],
      "layout": "IPY_MODEL_0ef51609179642868ef0bf206e15f4bc"
     }
    },
    "9cdbecb3c4cd498781a8bc2aa4908b79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f04f14dfe1934393aa0e0f5a1997d560",
      "placeholder": "​",
      "style": "IPY_MODEL_07534a33162147a18729b7ba809c6fa0",
      "value": "Loading weights: 100%"
     }
    },
    "7a9e86028b464db48aaa4ea2f091c73d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32373580d4a749fdbb1e883a633c1410",
      "max": 103,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d5922861d564afc89aedb8c0e4b3820",
      "value": 103
     }
    },
    "c451c251ecb04fe1b9d958356ebd7208": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36c27afb2b514dcc9161f223bfb1a6d1",
      "placeholder": "​",
      "style": "IPY_MODEL_89ce6627513340fb91b36ab40b89a4b7",
      "value": " 103/103 [00:00&lt;00:00, 513.95it/s, Materializing param=pooler.dense.weight]"
     }
    },
    "0ef51609179642868ef0bf206e15f4bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f04f14dfe1934393aa0e0f5a1997d560": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07534a33162147a18729b7ba809c6fa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32373580d4a749fdbb1e883a633c1410": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d5922861d564afc89aedb8c0e4b3820": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "36c27afb2b514dcc9161f223bfb1a6d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89ce6627513340fb91b36ab40b89a4b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}