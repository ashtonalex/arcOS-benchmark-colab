{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arcOS Benchmark - Causal QA with GNN + LLM\n",
    "\n",
    "**Phase 1: Environment & Data Foundation**\n",
    "\n",
    "This notebook implements the complete arcOS benchmark pipeline:\n",
    "- Graph Neural Network structural reasoning over knowledge graphs\n",
    "- LLM text generation with graph-guided prompts\n",
    "- Evaluation on RoG-WebQSP question answering dataset\n",
    "\n",
    "**Requirements:**\n",
    "- Google Colab with GPU runtime (T4 or better)\n",
    "- Google Drive mounted for checkpointing\n",
    "- ~10GB free space on Drive\n",
    "\n",
    "**Architecture:**\n",
    "- Dataset: RoG-WebQSP (4,706 QA pairs with Freebase subgraphs)\n",
    "- Graph DB: NetworkX in-memory\n",
    "- GNN: Graph Attention Network (GATv2)\n",
    "- LLM: OpenRouter API (Claude 3.5 Sonnet)\n",
    "- Verbalization: Hard prompts (text-based, not soft embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "total 1137483\n",
      "-rw------- 1 root root     22759 Jun 14  2020 001374 (1).ldb\n",
      "-rw------- 1 root root     22759 Jun 14  2020 001374.ldb\n",
      "-rw------- 1 root root   2123232 Jun 14  2020 001377.ldb\n",
      "-rw------- 1 root root   2137969 Jun 14  2020 001378.ldb\n",
      "-rw------- 1 root root     96516 Jun 14  2020 001379 (1).ldb\n",
      "-rw------- 1 root root     96516 Jun 14  2020 001379.ldb\n",
      "-rw------- 1 root root    493826 Jun 14  2020 001394 (1).ldb\n",
      "-rw------- 1 root root    493826 Jun 14  2020 001394.ldb\n",
      "-rw------- 1 root root   2120864 Jun 14  2020 001395.ldb\n",
      "-rw------- 1 root root   2110289 Jun 14  2020 001396.ldb\n",
      "-rw------- 1 root root    153657 Jun 14  2020 001397 (1).ldb\n",
      "-rw------- 1 root root    153657 Jun 14  2020 001397.ldb\n",
      "-rw------- 1 root root     83340 Jun 14  2020 001412 (1).ldb\n",
      "-rw------- 1 root root     83340 Jun 14  2020 001412.ldb\n",
      "-rw------- 1 root root      9232 Jun 14  2020 001427 (1).ldb\n",
      "-rw------- 1 root root      9232 Jun 14  2020 001427.ldb\n",
      "-rw------- 1 root root      3173 Jun 14  2020 001441 (1).ldb\n",
      "-rw------- 1 root root      3173 Jun 14  2020 001441.ldb\n",
      "-rw------- 1 root root      5777 Jun 14  2020 001470 (1).ldb\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# List folders in MyDrive to see what's there\n",
    "!ls -la /content/drive/MyDrive/ | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Environment Setup\n",
    "\n",
    "Install dependencies and verify GPU availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/content/arcOS-benchmark-colab'...\n",
      "remote: Enumerating objects: 36, done.\u001b[K\n",
      "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
      "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
      "remote: Total 36 (delta 2), reused 36 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (36/36), 66.09 KiB | 6.61 MiB/s, done.\n",
      "Resolving deltas: 100% (2/2), done.\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository into Colab\n",
    "!git clone https://github.com/ashtonalex/arcOS-benchmark-colab /content/arcOS-benchmark-colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 1: ENVIRONMENT PATH VERIFICATION\n",
      "======================================================================\n",
      "Current kernel executable: /usr/bin/python3\n",
      "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "Site packages: /content\n",
      "✓ UV available: uv 0.9.16\n",
      "\n",
      "======================================================================\n",
      "STEP 2: PACKAGE INSTALLATION\n",
      "======================================================================\n",
      "Installing packages using UV with --python /usr/bin/python3\n",
      "\n",
      "Installing PyTorch with CUDA 11.8 support...\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m3 packages\u001b[0m \u001b[2min 11ms\u001b[0m\u001b[0m\n",
      "\n",
      "Installing additional dependencies...\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 12ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 12ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m\n",
      "\n",
      "======================================================================\n",
      "STEP 3: INSTALLATION VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "Verifying installed packages:\n",
      "\n",
      "✓ torch        v2.9.0+cu126 \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/torch\n",
      "\n",
      "✓ datasets     v4.0.0       \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/datasets\n",
      "\n",
      "✓ networkx     v3.6.1       \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/networkx\n",
      "\n",
      "✓ tqdm         v4.67.2      \n",
      "  Location: /usr/local/lib/python3.12/dist-packages/tqdm\n",
      "\n",
      "======================================================================\n",
      "STEP 4: GPU VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "GPU available: True ✓\n",
      "GPU name: Tesla T4\n",
      "GPU memory: 15.83 GB\n",
      "CUDA version: 12.6\n",
      "\n",
      "======================================================================\n",
      "ENVIRONMENT SETUP SUMMARY\n",
      "======================================================================\n",
      "Package manager: UV\n",
      "Python executable: /usr/bin/python3\n",
      "All packages verified: ✓ YES\n",
      "GPU available: ✓ YES\n",
      "======================================================================\n",
      "\n",
      "✓ Environment setup complete with full parity!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENVIRONMENT SETUP WITH UV PACKAGE MANAGER\n",
    "# Ensures absolute environment parity between kernel and installed packages\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Colab UV workaround: Clear broken constraint files\n",
    "os.environ[\"UV_CONSTRAINT\"] = \"\"\n",
    "os.environ[\"UV_BUILD_CONSTRAINT\"] = \"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 1: ENVIRONMENT PATH VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Capture current Python executable\n",
    "current_python = sys.executable\n",
    "print(f\"Current kernel executable: {current_python}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Site packages: {sys.path[0] if sys.path else 'N/A'}\")\n",
    "\n",
    "# Check if uv is available\n",
    "def check_uv_available():\n",
    "    \"\"\"Check if uv is installed and accessible.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['uv', '--version'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        return result.returncode == 0\n",
    "    except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "        return False\n",
    "\n",
    "uv_available = check_uv_available()\n",
    "\n",
    "if not uv_available:\n",
    "    print(\"\\n⚠ UV not found. Installing uv package manager...\")\n",
    "    %pip install -q uv\n",
    "    uv_available = check_uv_available()\n",
    "\n",
    "if uv_available:\n",
    "    # Get uv version\n",
    "    uv_version = subprocess.run(\n",
    "        ['uv', '--version'],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    ).stdout.strip()\n",
    "    print(f\"✓ UV available: {uv_version}\")\n",
    "else:\n",
    "    print(\"✗ UV installation failed. Will fall back to pip.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: PACKAGE INSTALLATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define packages to install\n",
    "packages = [\n",
    "    \"datasets\",\n",
    "    \"networkx\",\n",
    "    \"tqdm\"\n",
    "]\n",
    "\n",
    "# PyTorch with CUDA support\n",
    "torch_packages = \"torch torchvision torchaudio\"\n",
    "torch_index = \"https://download.pytorch.org/whl/cu118\"\n",
    "\n",
    "if uv_available:\n",
    "    print(f\"Installing packages using UV with --python {current_python}\\n\")\n",
    "    \n",
    "    # Install PyTorch with CUDA\n",
    "    print(\"Installing PyTorch with CUDA 11.8 support...\")\n",
    "    !uv pip install --python {current_python} {torch_packages} --index-url {torch_index}\n",
    "    \n",
    "    # Install other packages\n",
    "    print(\"\\nInstalling additional dependencies...\")\n",
    "    for package in packages:\n",
    "        !uv pip install --python {current_python} {package}\n",
    "else:\n",
    "    print(\"Falling back to standard pip installation\\n\")\n",
    "    \n",
    "    # Install PyTorch with CUDA\n",
    "    print(\"Installing PyTorch with CUDA 11.8 support...\")\n",
    "    %pip install -q {torch_packages} --index-url {torch_index}\n",
    "    \n",
    "    # Install other packages\n",
    "    print(\"\\nInstalling additional dependencies...\")\n",
    "    %pip install -q {' '.join(packages)}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: INSTALLATION VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verify installed packages are in the correct location\n",
    "def verify_package_location(package_name):\n",
    "    \"\"\"Verify package is installed in current kernel's site-packages.\"\"\"\n",
    "    try:\n",
    "        module = __import__(package_name)\n",
    "        module_path = Path(module.__file__).parent\n",
    "        \n",
    "        # Check if module is in one of sys.path locations\n",
    "        in_sys_path = any(str(module_path).startswith(p) for p in sys.path if p)\n",
    "        \n",
    "        # Get version if available\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "        \n",
    "        return {\n",
    "            'installed': True,\n",
    "            'version': version,\n",
    "            'location': str(module_path),\n",
    "            'in_sys_path': in_sys_path\n",
    "        }\n",
    "    except ImportError:\n",
    "        return {'installed': False}\n",
    "\n",
    "# Verify key packages\n",
    "verification_packages = ['torch', 'datasets', 'networkx', 'tqdm']\n",
    "print(\"\\nVerifying installed packages:\\n\")\n",
    "\n",
    "all_verified = True\n",
    "for pkg in verification_packages:\n",
    "    info = verify_package_location(pkg)\n",
    "    if info['installed']:\n",
    "        status = \"✓\" if info['in_sys_path'] else \"⚠\"\n",
    "        print(f\"{status} {pkg:12s} v{info['version']:12s}\")\n",
    "        print(f\"  Location: {info['location']}\")\n",
    "        if not info['in_sys_path']:\n",
    "            print(f\"  WARNING: Not in sys.path!\")\n",
    "            all_verified = False\n",
    "    else:\n",
    "        print(f\"✗ {pkg:12s} NOT INSTALLED\")\n",
    "        all_verified = False\n",
    "    print()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 4: GPU VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import torch\n",
    "gpu_available = torch.cuda.is_available()\n",
    "print(f\"\\nGPU available: {gpu_available} {'✓' if gpu_available else '✗'}\")\n",
    "\n",
    "if gpu_available:\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"⚠ Warning: No GPU detected.\")\n",
    "    print(\"  Go to: Runtime -> Change runtime type -> Select T4 GPU\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENVIRONMENT SETUP SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Package manager: {'UV' if uv_available else 'pip'}\")\n",
    "print(f\"Python executable: {current_python}\")\n",
    "print(f\"All packages verified: {'✓ YES' if all_verified else '✗ NO'}\")\n",
    "print(f\"GPU available: {'✓ YES' if gpu_available else '✗ NO'}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if not all_verified:\n",
    "    print(\"\\n⚠ WARNING: Some packages failed verification. Check output above.\")\n",
    "else:\n",
    "    print(\"\\n✓ Environment setup complete with full parity!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Import Modules\n",
    "\n",
    "Import arcOS benchmark modules from `src/` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found project root: /content/arcOS-benchmark-colab\n",
      "  Current directory: /content\n",
      "\n",
      "Importing modules...\n",
      "✓ All imports successful\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Auto-detect project root (works with Colab, local Jupyter, and VSCode)\n",
    "# Try multiple strategies to find the project root\n",
    "possible_roots = []\n",
    "\n",
    "# Strategy 1: Check if we're in the notebooks/ folder\n",
    "if Path.cwd().name == \"notebooks\":\n",
    "    possible_roots.append(Path.cwd().parent)\n",
    "\n",
    "# Strategy 2: Check current directory\n",
    "possible_roots.append(Path.cwd())\n",
    "\n",
    "# Strategy 3: Check parent directory (for when running from notebooks/)\n",
    "possible_roots.append(Path.cwd().parent)\n",
    "\n",
    "# Strategy 4: Check if notebook file path is available (Jupyter/VSCode)\n",
    "try:\n",
    "    # Try to get the notebook's directory from IPython\n",
    "    from IPython import get_ipython\n",
    "    ipython = get_ipython()\n",
    "    if ipython and hasattr(ipython, 'user_ns'):\n",
    "        # In Jupyter/VSCode, __file__ might be available\n",
    "        notebook_path = ipython.user_ns.get('__vsc_ipynb_file__')\n",
    "        if notebook_path:\n",
    "            possible_roots.append(Path(notebook_path).parent.parent)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Strategy 5: Colab-specific paths\n",
    "possible_roots.extend([\n",
    "    Path(\"arcOS-benchmark-colab\"),\n",
    "    Path(\"/content/arcOS-benchmark-colab\"),\n",
    "    Path(\"/content\"),\n",
    "])\n",
    "\n",
    "# Remove duplicates while preserving order\n",
    "seen = set()\n",
    "unique_roots = []\n",
    "for root in possible_roots:\n",
    "    root_abs = root.resolve()\n",
    "    if root_abs not in seen:\n",
    "        seen.add(root_abs)\n",
    "        unique_roots.append(root)\n",
    "\n",
    "# Search for project root\n",
    "project_root = None\n",
    "for root in unique_roots:\n",
    "    try:\n",
    "        src_path = root / \"src\"\n",
    "        if src_path.exists() and (src_path / \"config.py\").exists():\n",
    "            project_root = root.resolve()\n",
    "            break\n",
    "    except (OSError, PermissionError):\n",
    "        continue\n",
    "\n",
    "if project_root is None:\n",
    "    print(\"⚠ ERROR: Could not find src/ directory\")\n",
    "    print(f\"Current directory: {Path.cwd()}\")\n",
    "    print(f\"\\nSearched in the following locations:\")\n",
    "    for i, root in enumerate(unique_roots, 1):\n",
    "        try:\n",
    "            abs_path = root.resolve()\n",
    "            exists = root.exists()\n",
    "            src_exists = (root / \"src\").exists() if exists else False\n",
    "            print(f\"  {i}. {abs_path} (exists: {exists}, has src/: {src_exists})\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {i}. {root} (error: {e})\")\n",
    "    raise ImportError(\"src/ not found - check project structure\")\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.insert(0, str(project_root))\n",
    "print(f\"✓ Found project root: {project_root}\")\n",
    "print(f\"  Current directory: {Path.cwd()}\")\n",
    "\n",
    "# Import modules\n",
    "print(\"\\nImporting modules...\")\n",
    "try:\n",
    "    from src.config import BenchmarkConfig\n",
    "    from src.utils.seeds import set_seeds\n",
    "    from src.utils.checkpoints import (\n",
    "        ensure_drive_mounted,\n",
    "        checkpoint_exists,\n",
    "        save_checkpoint,\n",
    "        load_checkpoint,\n",
    "        create_checkpoint_dirs,\n",
    "    )\n",
    "    from src.data.dataset_loader import RoGWebQSPLoader\n",
    "    from src.data.graph_builder import GraphBuilder\n",
    "    print(\"✓ All imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Import failed: {e}\")\n",
    "    print(f\"Project root: {project_root}\")\n",
    "    print(f\"sys.path: {sys.path[:3]}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Configuration\n",
    "\n",
    "Initialize benchmark configuration with hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "arcOS Benchmark Configuration\n",
      "============================================================\n",
      "Seed: 42 (deterministic=True)\n",
      "Dataset: rmanluo/RoG-webqsp\n",
      "Drive root: /content/drive/MyDrive/arcOS_benchmark\n",
      "Checkpoint dir: /content/drive/MyDrive/arcOS_benchmark/checkpoints\n",
      "Results dir: /content/drive/MyDrive/arcOS_benchmark/results\n",
      "\n",
      "--- Retrieval ---\n",
      "Embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Top-K entities: 10\n",
      "PCST budget: 50\n",
      "\n",
      "--- GNN ---\n",
      "Hidden dim: 256\n",
      "Num layers: 3\n",
      "Num heads: 4\n",
      "Pooling: attention\n",
      "\n",
      "--- LLM ---\n",
      "Model: anthropic/claude-3.5-sonnet\n",
      "Provider: openrouter\n",
      "Temperature: 0.0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize configuration\n",
    "config = BenchmarkConfig(\n",
    "    seed=42,\n",
    "    deterministic=True,\n",
    "    drive_root=\"/content/drive/MyDrive/arcOS_benchmark\",\n",
    ")\n",
    "\n",
    "# Print configuration summary\n",
    "config.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Seed Initialization\n",
    "\n",
    "Set random seeds for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random seeds set to 42 (deterministic=True)\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "set_seeds(config.seed, config.deterministic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Google Drive Setup\n",
    "\n",
    "Mount Google Drive and create checkpoint/results directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Google Drive already mounted at /content/drive\n",
      "✓ Checkpoint directory: /content/drive/MyDrive/arcOS_benchmark/checkpoints\n",
      "✓ Results directory: /content/drive/MyDrive/arcOS_benchmark/results\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "drive_mounted = ensure_drive_mounted()\n",
    "\n",
    "if drive_mounted:\n",
    "    # Create checkpoint and results directories\n",
    "    create_checkpoint_dirs(config.checkpoint_dir, config.results_dir)\n",
    "else:\n",
    "    print(\"⚠ Warning: Drive not mounted. Checkpointing will not work.\")\n",
    "    print(\"  Continuing with local /content/ storage (temporary)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Dataset Loading\n",
    "\n",
    "Load RoG-WebQSP dataset from HuggingFace with Drive caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ HuggingFace cache directory: /content/drive/MyDrive/arcOS_benchmark/checkpoints/huggingface_cache\n",
      "Loading dataset from checkpoint...\n",
      "✓ Checkpoint loaded: /content/drive/MyDrive/arcOS_benchmark/checkpoints/dataset.pkl (pickle)\n",
      "\n",
      "============================================================\n",
      "Dataset Schema Inspection\n",
      "============================================================\n",
      "Inspecting first split: train\n",
      "\n",
      "Fields:\n",
      "  - id: Value('string')\n",
      "  - question: Value('string')\n",
      "  - answer: List(Value('string'))\n",
      "  - q_entity: List(Value('string'))\n",
      "  - a_entity: List(Value('string'))\n",
      "  - graph: List(List(Value('string')))\n",
      "  - choices: List(Value('null'))\n",
      "\n",
      "ℹ Additional fields found: {'choices'}\n",
      "\n",
      "✓ All expected fields present\n",
      "\n",
      "Sample Examples (first 1):\n",
      "\n",
      "--- Example 0 ---\n",
      "ID: WebQTrn-0\n",
      "Question: what is the name of justin bieber brother\n",
      "Answer: ['Jaxon Bieber']\n",
      "Question Entity: ['Justin Bieber']\n",
      "Answer Entity: ['Jaxon Bieber']\n",
      "Graph: 9088 triples\n",
      "  Sample triple: ['P!nk', 'freebase.valuenotation.is_reviewed', 'Gender']\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Dataset Statistics\n",
      "============================================================\n",
      "\n",
      "--- train ---\n",
      "Total examples: 2826\n",
      "Graph size (triples):\n",
      "  - Average: 4229.2\n",
      "  - Min: 28\n",
      "  - Max: 10818\n",
      "\n",
      "--- validation ---\n",
      "Total examples: 246\n",
      "Graph size (triples):\n",
      "  - Average: 4141.7\n",
      "  - Min: 0\n",
      "  - Max: 9496\n",
      "\n",
      "--- test ---\n",
      "Total examples: 1628\n",
      "Graph size (triples):\n",
      "  - Average: 4309.3\n",
      "  - Min: 2\n",
      "  - Max: 10810\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Dataset Split Validation\n",
      "============================================================\n",
      "Train: 2826 ✗ (expected 2830)\n",
      "Validation: 246 ✓\n",
      "Test: 1628 ✗ (expected 1630)\n",
      "\n",
      "✗ Split size mismatch detected\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize dataset loader\n",
    "cache_dir = config.checkpoint_dir / \"huggingface_cache\"\n",
    "loader = RoGWebQSPLoader(cache_dir=cache_dir)\n",
    "\n",
    "# Check for cached dataset\n",
    "dataset_checkpoint_path = config.get_checkpoint_path(\"dataset.pkl\")\n",
    "\n",
    "if checkpoint_exists(dataset_checkpoint_path):\n",
    "    print(\"Loading dataset from checkpoint...\")\n",
    "    dataset = load_checkpoint(dataset_checkpoint_path, format=\"pickle\")\n",
    "else:\n",
    "    print(\"Downloading dataset from HuggingFace...\")\n",
    "    dataset = loader.load(dataset_name=config.dataset_name)\n",
    "    save_checkpoint(dataset, dataset_checkpoint_path, format=\"pickle\")\n",
    "\n",
    "# Inspect dataset schema\n",
    "loader.inspect_schema(dataset, num_examples=1)\n",
    "\n",
    "# Compute statistics\n",
    "loader.compute_statistics(dataset)\n",
    "\n",
    "# Validate split counts\n",
    "split_valid = loader.validate_split_counts(\n",
    "    dataset,\n",
    "    expected_train=config.expected_train_size,\n",
    "    expected_val=config.expected_val_size,\n",
    "    expected_test=config.expected_test_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Graph Construction\n",
    "\n",
    "Build NetworkX graphs from dataset triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GraphBuilder initialized (directed=True)\n",
      "Building unified graph from training split...\n",
      "Building unified graph from dataset...\n",
      "  Processed 500/2826 examples...\n",
      "  Processed 1000/2826 examples...\n",
      "  Processed 1500/2826 examples...\n",
      "  Processed 2000/2826 examples...\n",
      "  Processed 2500/2826 examples...\n",
      "✓ Unified graph built from 2826 examples\n",
      "  Total triples processed: 11951780\n",
      "  Unique nodes: 1023103\n",
      "  Unique edges: 2889277\n",
      "✓ Checkpoint saved: /content/drive/MyDrive/arcOS_benchmark/checkpoints/unified_graph.pkl (pickle)\n",
      "\n",
      "============================================================\n",
      "Unified Training Graph Information\n",
      "============================================================\n",
      "Nodes: 1023103\n",
      "Edges: 2889277\n",
      "Directed: True\n",
      "Density: 0.000003\n",
      "Weakly connected: True\n",
      "\n",
      "Relation Statistics:\n",
      "Unique relations: 5622\n",
      "Top 10 relations:\n",
      "  - common.topic.notable_types: 135525\n",
      "  - common.topic.notable_for: 70887\n",
      "  - location.location.containedby: 67294\n",
      "  - freebase.valuenotation.is_reviewed: 67203\n",
      "  - people.person.profession: 44770\n",
      "  - location.statistical_region.population: 42123\n",
      "  - common.topic.article: 41886\n",
      "  - people.person.gender: 40946\n",
      "  - common.topic.webpage: 38099\n",
      "  - common.webpage.topic: 38029\n",
      "\n",
      "Degree Statistics:\n",
      "Average in-degree: 2.82\n",
      "Average out-degree: 2.82\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Graph Size Validation\n",
      "============================================================\n",
      "Nodes: 1023103 ✓\n",
      "Edges: 2889277 ✓\n",
      "\n",
      "✓ Graph meets size requirements\n",
      "============================================================\n",
      "\n",
      "Building sample per-example graph...\n",
      "\n",
      "============================================================\n",
      "Sample Per-Example Graph Information\n",
      "============================================================\n",
      "Nodes: 1723\n",
      "Edges: 8286\n",
      "Directed: True\n",
      "Density: 0.002793\n",
      "Weakly connected: True\n",
      "\n",
      "Relation Statistics:\n",
      "Unique relations: 320\n",
      "Top 10 relations:\n",
      "  - freebase.valuenotation.is_reviewed: 898\n",
      "  - broadcast.content.artist: 771\n",
      "  - music.artist.genre: 742\n",
      "  - broadcast.artist.content: 631\n",
      "  - people.person.profession: 614\n",
      "  - common.topic.notable_types: 395\n",
      "  - people.person.gender: 208\n",
      "  - people.person.nationality: 179\n",
      "  - broadcast.content.genre: 136\n",
      "  - common.topic.notable_for: 135\n",
      "\n",
      "Degree Statistics:\n",
      "Average in-degree: 4.81\n",
      "Average out-degree: 4.81\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize graph builder\n",
    "graph_builder = GraphBuilder(directed=config.graph_directed)\n",
    "\n",
    "# Check for cached unified graph\n",
    "unified_graph_path = config.get_checkpoint_path(\"unified_graph.pkl\")\n",
    "\n",
    "if checkpoint_exists(unified_graph_path):\n",
    "    print(\"Loading unified graph from checkpoint...\")\n",
    "    unified_graph = load_checkpoint(unified_graph_path, format=\"pickle\")\n",
    "else:\n",
    "    print(\"Building unified graph from training split...\")\n",
    "    unified_graph = graph_builder.build_unified_graph(dataset[\"train\"])\n",
    "    save_checkpoint(unified_graph, unified_graph_path, format=\"pickle\")\n",
    "\n",
    "# Print graph statistics\n",
    "graph_builder.print_graph_info(unified_graph, name=\"Unified Training Graph\")\n",
    "\n",
    "# Validate graph size\n",
    "graph_valid = graph_builder.validate_graph_size(\n",
    "    unified_graph,\n",
    "    min_nodes=config.unified_graph_min_nodes,\n",
    "    min_edges=config.unified_graph_min_edges,\n",
    ")\n",
    "\n",
    "# Build sample per-example graph for demonstration\n",
    "print(\"\\nBuilding sample per-example graph...\")\n",
    "sample_example = dataset[\"train\"][0]\n",
    "sample_graph = graph_builder.build_from_triples(\n",
    "    sample_example[\"graph\"],\n",
    "    graph_id=sample_example[\"id\"]\n",
    ")\n",
    "graph_builder.print_graph_info(sample_graph, name=\"Sample Per-Example Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Phase 1 Validation\n",
    "\n",
    "Automated validation of all Phase 1 success criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Phase 1 Success Criteria Validation\n",
      "============================================================\n",
      "✓ Checkpoint saved: /content/drive/MyDrive/arcOS_benchmark/checkpoints/test_roundtrip.pkl (pickle)\n",
      "✓ Checkpoint loaded: /content/drive/MyDrive/arcOS_benchmark/checkpoints/test_roundtrip.pkl (pickle)\n",
      "\n",
      "Validation Results:\n",
      "  ✓ GPU Available\n",
      "  ✓ All Imports Successful\n",
      "  ✗ Dataset Splits Valid\n",
      "  ✓ Unified Graph Size Valid\n",
      "  ✓ Checkpoint Round-Trip\n",
      "\n",
      "============================================================\n",
      "✗ PHASE 1 INCOMPLETE - Some criteria failed\n",
      "\n",
      "Please review failed criteria above\n",
      "============================================================\n",
      "\n",
      "Phase 1 Summary:\n",
      "  Dataset: rmanluo/RoG-webqsp\n",
      "  Training examples: 2826\n",
      "  Validation examples: 246\n",
      "  Test examples: 1628\n",
      "  Unified graph nodes: 1023103\n",
      "  Unified graph edges: 2889277\n",
      "  Checkpoints saved to: /content/drive/MyDrive/arcOS_benchmark/checkpoints\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Phase 1 Success Criteria Validation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Collect validation results\n",
    "validation_results = {\n",
    "    \"GPU Available\": torch.cuda.is_available(),\n",
    "    \"All Imports Successful\": True,  # If we got here, imports worked\n",
    "    \"Dataset Splits Valid\": split_valid,\n",
    "    \"Unified Graph Size Valid\": graph_valid,\n",
    "}\n",
    "\n",
    "# Test checkpoint round-trip\n",
    "test_checkpoint_path = config.get_checkpoint_path(\"test_roundtrip.pkl\")\n",
    "test_data = {\"test\": \"round-trip\", \"value\": 42}\n",
    "try:\n",
    "    save_checkpoint(test_data, test_checkpoint_path, format=\"pickle\")\n",
    "    loaded_data = load_checkpoint(test_checkpoint_path, format=\"pickle\")\n",
    "    checkpoint_roundtrip_ok = (loaded_data == test_data)\n",
    "    validation_results[\"Checkpoint Round-Trip\"] = checkpoint_roundtrip_ok\n",
    "except Exception as e:\n",
    "    print(f\"Checkpoint round-trip failed: {e}\")\n",
    "    validation_results[\"Checkpoint Round-Trip\"] = False\n",
    "\n",
    "# Print results\n",
    "print(\"\\nValidation Results:\")\n",
    "all_passed = True\n",
    "for criterion, passed in validation_results.items():\n",
    "    status = \"✓\" if passed else \"✗\"\n",
    "    print(f\"  {status} {criterion}\")\n",
    "    if not passed:\n",
    "        all_passed = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_passed:\n",
    "    print(\"✓ PHASE 1 COMPLETE - All criteria passed!\")\n",
    "    print(\"\\nReady to proceed to Phase 2: Retrieval Pipeline\")\n",
    "else:\n",
    "    print(\"✗ PHASE 1 INCOMPLETE - Some criteria failed\")\n",
    "    print(\"\\nPlease review failed criteria above\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nPhase 1 Summary:\")\n",
    "print(f\"  Dataset: {config.dataset_name}\")\n",
    "print(f\"  Training examples: {len(dataset['train'])}\")\n",
    "print(f\"  Validation examples: {len(dataset['validation'])}\")\n",
    "print(f\"  Test examples: {len(dataset['test'])}\")\n",
    "print(f\"  Unified graph nodes: {unified_graph.number_of_nodes()}\")\n",
    "print(f\"  Unified graph edges: {unified_graph.number_of_edges()}\")\n",
    "print(f\"  Checkpoints saved to: {config.checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Build Retrieval Pipeline\n",
    "\n",
    "Initialize retrieval components (embeddings, FAISS index, PCST solver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PHASE 2: RETRIEVAL PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from src.retrieval import Retriever\n",
    "\n",
    "# Build retriever (uses checkpoints if available)\n",
    "retriever = Retriever.build_from_checkpoint_or_new(\n",
    "    config=config,\n",
    "    unified_graph=unified_graph  # From Phase 1 Cell 7\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Retrieval pipeline initialized\")\n",
    "print(f\"  - Entity embeddings: {len(retriever.entity_index)} entities\")\n",
    "print(f\"  - Top-K: {config.top_k_entities}\")\n",
    "print(f\"  - PCST budget: {config.pcst_budget} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Retrieval Validation\n",
    "\n",
    "Test retrieval pipeline on 10 validation examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RETRIEVAL VALIDATION (10 examples)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use first 10 validation examples\n",
    "val_examples = dataset[\"validation\"][:10]\n",
    "\n",
    "hit_count = 0\n",
    "total_time_ms = 0\n",
    "subgraph_sizes = []\n",
    "\n",
    "for i, example in enumerate(val_examples):\n",
    "    question = example[\"question\"]\n",
    "    answer_entities = example.get(\"a_entity\", [])\n",
    "    if isinstance(answer_entities, str):\n",
    "        answer_entities = [answer_entities]\n",
    "\n",
    "    # Retrieve subgraph\n",
    "    result = retriever.retrieve(question)\n",
    "\n",
    "    # Check if answer entity in subgraph\n",
    "    subgraph_nodes = set(result.subgraph.nodes())\n",
    "    hit = any(ans in subgraph_nodes for ans in answer_entities)\n",
    "\n",
    "    if hit:\n",
    "        hit_count += 1\n",
    "\n",
    "    total_time_ms += result.retrieval_time_ms\n",
    "    subgraph_sizes.append(result.num_nodes)\n",
    "\n",
    "    # Print example\n",
    "    print(f\"\\n[{i+1}/10] Q: {question[:60]}...\")\n",
    "    print(f\"  Answer entities: {answer_entities}\")\n",
    "    print(f\"  Subgraph: {result.num_nodes} nodes, {result.num_edges} edges\")\n",
    "    print(f\"  Hit: {'✓' if hit else '✗'}\")\n",
    "    print(f\"  Time: {result.retrieval_time_ms:.1f}ms\")\n",
    "\n",
    "# Summary metrics\n",
    "hit_rate = hit_count / len(val_examples) * 100\n",
    "avg_time = total_time_ms / len(val_examples)\n",
    "avg_size = sum(subgraph_sizes) / len(subgraph_sizes)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Hit rate: {hit_rate:.1f}% ({hit_count}/{len(val_examples)})\")\n",
    "print(f\"Avg retrieval time: {avg_time:.1f}ms\")\n",
    "print(f\"Avg subgraph size: {avg_size:.1f} nodes\")\n",
    "print(f\"Max subgraph size: {max(subgraph_sizes)} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Phase 2 Success Criteria\n",
    "\n",
    "Validate Phase 2 completion criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PHASE 2 SUCCESS CRITERIA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Criterion 1: Retrieval speed < 1 second\n",
    "speed_pass = avg_time < 1000  # ms\n",
    "print(f\"[{'✓' if speed_pass else '✗'}] Retrieval completes in <1 second: {avg_time:.1f}ms\")\n",
    "\n",
    "# Criterion 2: Hit rate > 60%\n",
    "hit_pass = hit_rate >= 60.0\n",
    "print(f\"[{'✓' if hit_pass else '✗'}] Subgraph contains answer entity >60%: {hit_rate:.1f}%\")\n",
    "\n",
    "# Criterion 3: All subgraphs connected\n",
    "all_connected = all(\n",
    "    nx.is_weakly_connected(retriever.retrieve(example[\"question\"]).subgraph)\n",
    "    for example in val_examples[:5]  # Check first 5\n",
    ")\n",
    "print(f\"[{'✓' if all_connected else '✗'}] All subgraphs are connected\")\n",
    "\n",
    "# Criterion 4: Subgraph size respects budget\n",
    "size_pass = max(subgraph_sizes) <= config.pcst_budget\n",
    "print(f\"[{'✓' if size_pass else '✗'}] Subgraph size ≤ budget ({max(subgraph_sizes)} ≤ {config.pcst_budget})\")\n",
    "\n",
    "# Overall pass\n",
    "all_pass = speed_pass and hit_pass and all_connected and size_pass\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if all_pass:\n",
    "    print(\"✓ PHASE 2 COMPLETE - All criteria met!\")\n",
    "    print(\"\\nReady to proceed to Phase 3: GNN Encoder\")\n",
    "else:\n",
    "    print(\"⚠ PHASE 2 INCOMPLETE - Review failed criteria above\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Build Retrieval Pipeline\n",
    "\n",
    "Initialize retrieval components (embeddings, FAISS index, PCST solver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PHASE 2: RETRIEVAL PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from src.retrieval import Retriever\n",
    "\n",
    "# Build retriever (uses checkpoints if available)\n",
    "retriever = Retriever.build_from_checkpoint_or_new(\n",
    "    config=config,\n",
    "    unified_graph=unified_graph  # From Phase 1 Cell 7\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Retrieval pipeline initialized\")\n",
    "print(f\"  - Entity embeddings: {len(retriever.entity_index)} entities\")\n",
    "print(f\"  - Top-K: {config.top_k_entities}\")\n",
    "print(f\"  - PCST budget: {config.pcst_budget} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Retrieval Validation\n",
    "\n",
    "Test retrieval pipeline on 10 validation examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RETRIEVAL VALIDATION (10 examples)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use first 10 validation examples\n",
    "val_examples = dataset[\"validation\"][:10]\n",
    "\n",
    "hit_count = 0\n",
    "total_time_ms = 0\n",
    "subgraph_sizes = []\n",
    "\n",
    "for i, example in enumerate(val_examples):\n",
    "    question = example[\"question\"]\n",
    "    answer_entities = example.get(\"a_entity\", [])\n",
    "    if isinstance(answer_entities, str):\n",
    "        answer_entities = [answer_entities]\n",
    "\n",
    "    # Retrieve subgraph\n",
    "    result = retriever.retrieve(question)\n",
    "\n",
    "    # Check if answer entity in subgraph\n",
    "    subgraph_nodes = set(result.subgraph.nodes())\n",
    "    hit = any(ans in subgraph_nodes for ans in answer_entities)\n",
    "\n",
    "    if hit:\n",
    "        hit_count += 1\n",
    "\n",
    "    total_time_ms += result.retrieval_time_ms\n",
    "    subgraph_sizes.append(result.num_nodes)\n",
    "\n",
    "    # Print example\n",
    "    print(f\"\\n[{i+1}/10] Q: {question[:60]}...\")\n",
    "    print(f\"  Answer entities: {answer_entities}\")\n",
    "    print(f\"  Subgraph: {result.num_nodes} nodes, {result.num_edges} edges\")\n",
    "    print(f\"  Hit: {'✓' if hit else '✗'}\")\n",
    "    print(f\"  Time: {result.retrieval_time_ms:.1f}ms\")\n",
    "\n",
    "# Summary metrics\n",
    "hit_rate = hit_count / len(val_examples) * 100\n",
    "avg_time = total_time_ms / len(val_examples)\n",
    "avg_size = sum(subgraph_sizes) / len(subgraph_sizes)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Hit rate: {hit_rate:.1f}% ({hit_count}/{len(val_examples)})\")\n",
    "print(f\"Avg retrieval time: {avg_time:.1f}ms\")\n",
    "print(f\"Avg subgraph size: {avg_size:.1f} nodes\")\n",
    "print(f\"Max subgraph size: {max(subgraph_sizes)} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Phase 2 Success Criteria\n",
    "\n",
    "Validate Phase 2 completion criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PHASE 2 SUCCESS CRITERIA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Criterion 1: Retrieval speed < 1 second\n",
    "speed_pass = avg_time < 1000  # ms\n",
    "print(f\"[{'✓' if speed_pass else '✗'}] Retrieval completes in <1 second: {avg_time:.1f}ms\")\n",
    "\n",
    "# Criterion 2: Hit rate > 60%\n",
    "hit_pass = hit_rate >= 60.0\n",
    "print(f\"[{'✓' if hit_pass else '✗'}] Subgraph contains answer entity >60%: {hit_rate:.1f}%\")\n",
    "\n",
    "# Criterion 3: All subgraphs connected\n",
    "all_connected = all(\n",
    "    nx.is_weakly_connected(retriever.retrieve(example[\"question\"]).subgraph)\n",
    "    for example in val_examples[:5]  # Check first 5\n",
    ")\n",
    "print(f\"[{'✓' if all_connected else '✗'}] All subgraphs are connected\")\n",
    "\n",
    "# Criterion 4: Subgraph size respects budget\n",
    "size_pass = max(subgraph_sizes) <= config.pcst_budget\n",
    "print(f\"[{'✓' if size_pass else '✗'}] Subgraph size ≤ budget ({max(subgraph_sizes)} ≤ {config.pcst_budget})\")\n",
    "\n",
    "# Overall pass\n",
    "all_pass = speed_pass and hit_pass and all_connected and size_pass\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if all_pass:\n",
    "    print(\"✓ PHASE 2 COMPLETE - All criteria met!\")\n",
    "    print(\"\\nReady to proceed to Phase 3: GNN Encoder\")\n",
    "else:\n",
    "    print(\"⚠ PHASE 2 INCOMPLETE - Review failed criteria above\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}